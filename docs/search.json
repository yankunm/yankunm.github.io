[
  {
    "objectID": "work/textbooks/danFleisch.html",
    "href": "work/textbooks/danFleisch.html",
    "title": "Maxwell’s Equations - Dan Fleisch",
    "section": "",
    "text": "Website: Official Website\n\n\n\n\n\n\nExpand\n\n\nWhat are the two kinds of Electric Fields in Maxwell’s Equation?\n\n\n\nAnswer\n\n\nElectrostatic Fields (from electric charge)\nInduced Electric Field (from changing magnetic field)\n\n\n\nWhat type of fields does Gauss’s law deal with?\n\n\n\nAnswer\n\nElectrostatic Fields (from electric charge)\n\n\n\n\n\n\n\nExpand\n\nElectric charge produces an electric field. The flux of that field passing through any closed surface is proportional to the total charge contained within that surface.\n\\[\\oint_S \\vec{E} \\cdot \\hat{n} da = \\frac{q_{enc}}{\\epsilon_0}\\]\n\n\n\n\n\n\nExpand To Learn About Left Hand Side\n\n\n\n\n\n\n\nWhat does the left hand side represent?\n\n\n\nAnswer\n\nThe number of electric field lines (AKA electric flux) passing through a closed surface \\(S\\).\n\n\nWhat is Electric field?\n\n\n\nAnswer\n\nThe electrical force exerted on one coulomb of charge at that point in space is the electric field at that location.\n\\[\\vec{E} = \\frac{\\vec{F}_e}{q_0}\\]\n\\(\\vec{E}\\) has units of \\(\\frac{N}{C} = \\frac{V}{m}\\)\nSpacing of electric field lines tells you the strength of it.\n\nElectric field lines go from positive to negative\nElectric field lines vector sums, so they never cross\n\n\n\nWhy do physicists and engineers always talk about small test charges?\n\n\n\nAnswer\n\nBecause the job of this charge is to test the electric field at a location, not to add another electric field into the mix (although you can’t stop it from doing so). Making the test charge infinitesimally small minimizes the effect of the test charge’s own field.\n\n\nWhat is the dot product? Why are we taking the dot product between \\(\\vec{E}\\) and \\(\\hat{n}\\) in Gauss’s Law?\n\n\n\nAnswer\n\nConsider vectors \\(\\vec{A}\\) and \\(\\vec{B}\\) in space.\nWhat is the projection of \\(\\vec{A}\\) onto \\(\\vec{B}\\)? From trig, it’s \\(|A| \\cos \\theta\\).\nNow the dot product is that projection, multiplied by the magnitude of \\(\\vec{B}\\).\n\\[\\vec{A} \\cdot \\vec{B} = |A| |B| \\cos \\theta\\]\n\n\nWhat is \\(\\hat{n}\\)?\n\n\n\nAnswer\n\nIt is the unit normal vector, which has a length of one, and points in the direction perpendicular to the surface.\nNote that since \\(da\\) is the tiny amount of area we are considering\n\\[\\hat{n} da = d \\vec{a}\\]\n\n\nWhat is the difference between closed surface and open surface?\n\n\n\nAnswer\n\n\nOpen Surface - any surface for which it is possible to get from one side to the other without going through the surface\nClosed Surface - a surface that divides space into an “inside” and “outside”. Unit Normal Vector \\(\\hat{n}\\) always points outwards, away from the volume enclosed by the surface.\n\n\n\nWhat does \\(\\vec{E} \\cdot \\hat{n}\\) represent?\n\n\n\nAnswer\n\nThe component of the electric field vector that is perpendicular to the surface.\n\\[\\vec{E} \\cdot \\hat{n} = |\\vec{E}| \\cos \\theta\\]\n\n\nHow do you find the mass of a surface with varying density function \\(\\sigma(x, y)\\)?\n\n\n\nAnswer\n\nSince mass is density times volume, we can write:\n\\[Mass = \\sigma \\cdot Area\\]\n\\[Mass_S = \\Sigma_{i = 1}^{N} \\sigma_i \\cdot Area_i\\]\nIf we let Areas to become infinitesimally small \\(dA\\), we get \\[Mass = \\int_{S} \\sigma dA\\]\nThis is a surface intergal.\n\n\nWhat does \\(\\int_S \\vec{A} \\cdot \\hat{n} da\\) represent?\n\n\n\nAnswer\n\nIt represents the flux of a vector field.\nWhat’s a vector field?\nIt is magnitude and direction quantities distributed in space.\n\nScalar Field - something like temperature distribution in a room, where at each point theres a number\nVector Field - something like flow of fluid, there at every point it has a speed and direction\n\n\n\nWhat’s flux \\(\\Phi\\)?\n\n\n\nAnswer\n\nFlux \\(\\Phi\\) of a field over a surface is the amount of flow through that surface.\n\\[\\Phi = \\vec{A} \\cdot \\hat{n} \\times (Surface Area)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExpand To Learn About Right Hand Side\n\n\n\n\n\n\nWhat is the right hand side in words?\n\n\n\nAnswer\n\nThe total amount of enclosed charge normalized by the permittivity of free space.\n\n\nWhat is \\(\\epsilon_0\\) and why is it there?\n\n\n\nAnswer\n\nIt is called the permitivity of free space or “vacuum permitivity”.\n\\[\\epsilon_0 = 8.854 \\times 10^{-12} \\frac{F}{m}\\]\nWhen we say the permitivity of a material, when are referring to its reponse to an electric field. It is also the key parameter in determining the speed at which an electromagnetic wave propagates through that medium.\nHigh permitivity means it provides higher capacitance.\nIn Gauss’s Law, \\(\\epsilon_0\\) acts as a proportionality constant that relates electric flux to enclosed charge.\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nFive point charges are enclosed in a cylindrical surface \\(S\\). If the values of the charges are \\(q_1 = +3 nC\\), \\(q_2 = -2 nC\\), \\(q_3 = +2 nC\\), \\(q_4 = +4 nC\\), and \\(q_5 = -1 nC\\), find the total flux through \\(S\\).\n\n\n\nAnswer\n\n\\[\\sum_{i=1}^{5} q_i = 3 - 2 + 2 + 4 - 1 = 6 nC = 6 \\times 10^{-9} C\\]\n\\[\\Phi_E = \\frac{q_enc}{\\epsilon_0} = \\frac{6 \\times 10^{-9}C}{8.854 \\times 10^{-12} \\frac{C}{V \\cdot m}} = \\boxed{678 \\hspace{1mm} Vm}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExpand\n\nThe electric field produced by electric diverges from positive charge and converges upon negative charge.\n\\[\\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\epsilon_0}\\]\n\n\n\n\n\n\nExpand To Learn About Left Hand Side\n\n\n\n\n\n\n\nWhat does the left hand side represent?\n\n\n\nAnswer\n\n\nThe tendency of electric field to flow away from a point in space - AKA the divergence.\n\n\nWhat is the difference between differential and integral form of Gauss’s Law?\n\n\n\nAnswer\n\n\nDifferential deals with individual points in space, whereareas integral deals with a closed surface.\n\n\nWhat is \\(\\vec{\\nabla}\\)?\n\n\n\nAnswer\n\n\nIt is called “del” or “nabla”. It tells you to take the derivative of what ever quantity comes after it.\n\\[\\vec{\\nabla} =\\hat{i} \\frac{\\partial}{\\partial x} + \\hat{j} \\frac{\\partial}{\\partial y} + \\hat{k} \\frac{\\partial}{\\partial z}\n\\]\nIt is an mathematical operator, which just means that it needs something to act on and cannot just appear by itself.\n\\(\\vec{\\nabla}\\) is gradient, \\(\\vec{\\nabla} \\cdot\\) is divergence, and \\(\\vec{\\nabla} \\times\\) is curl.\n\n\nWhat is \\(\\vec{\\nabla} \\cdot\\) specifically?\n\n\n\nExpand\n\nOliver Heaviside suggested the word “divergence” to describe the rate at which electric field flow outwards from a positive charge.\n\nsource - diverge from that point (positive charge for electric field)\nsink - converge to that point (negative charge for magnetic field)\n\n\n\n\n\n\n\n\n\n\n\n\nExpand To Learn About Right Hand Side\n\n\n\n\n\n\nWhat is the right hand side in words?\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nFive point charges are enclosed in a cylindrical surface \\(S\\). If the values of the charges are \\(q_1 = +3 nC\\), \\(q_2 = -2 nC\\), \\(q_3 = +2 nC\\), \\(q_4 = +4 nC\\), and \\(q_5 = -1 nC\\), find the total flux through \\(S\\).\n\n\n\nAnswer\n\n\\[\\sum_{i=1}^{5} q_i = 3 - 2 + 2 + 4 - 1 = 6 nC = 6 \\times 10^{-9} C\\]\n\\[\\Phi_E = \\frac{q_enc}{\\epsilon_0} = \\frac{6 \\times 10^{-9}C}{8.854 \\times 10^{-12} \\frac{C}{V \\cdot m}} = \\boxed{678 \\hspace{1mm} Vm}\\]"
  },
  {
    "objectID": "work/textbooks/danFleisch.html#gausss-law-for-electric-fields",
    "href": "work/textbooks/danFleisch.html#gausss-law-for-electric-fields",
    "title": "Maxwell’s Equations - Dan Fleisch",
    "section": "",
    "text": "Expand\n\n\nWhat are the two kinds of Electric Fields in Maxwell’s Equation?\n\n\n\nAnswer\n\n\nElectrostatic Fields (from electric charge)\nInduced Electric Field (from changing magnetic field)\n\n\n\nWhat type of fields does Gauss’s law deal with?\n\n\n\nAnswer\n\nElectrostatic Fields (from electric charge)\n\n\n\n\n\n\n\nExpand\n\nElectric charge produces an electric field. The flux of that field passing through any closed surface is proportional to the total charge contained within that surface.\n\\[\\oint_S \\vec{E} \\cdot \\hat{n} da = \\frac{q_{enc}}{\\epsilon_0}\\]\n\n\n\n\n\n\nExpand To Learn About Left Hand Side\n\n\n\n\n\n\n\nWhat does the left hand side represent?\n\n\n\nAnswer\n\nThe number of electric field lines (AKA electric flux) passing through a closed surface \\(S\\).\n\n\nWhat is Electric field?\n\n\n\nAnswer\n\nThe electrical force exerted on one coulomb of charge at that point in space is the electric field at that location.\n\\[\\vec{E} = \\frac{\\vec{F}_e}{q_0}\\]\n\\(\\vec{E}\\) has units of \\(\\frac{N}{C} = \\frac{V}{m}\\)\nSpacing of electric field lines tells you the strength of it.\n\nElectric field lines go from positive to negative\nElectric field lines vector sums, so they never cross\n\n\n\nWhy do physicists and engineers always talk about small test charges?\n\n\n\nAnswer\n\nBecause the job of this charge is to test the electric field at a location, not to add another electric field into the mix (although you can’t stop it from doing so). Making the test charge infinitesimally small minimizes the effect of the test charge’s own field.\n\n\nWhat is the dot product? Why are we taking the dot product between \\(\\vec{E}\\) and \\(\\hat{n}\\) in Gauss’s Law?\n\n\n\nAnswer\n\nConsider vectors \\(\\vec{A}\\) and \\(\\vec{B}\\) in space.\nWhat is the projection of \\(\\vec{A}\\) onto \\(\\vec{B}\\)? From trig, it’s \\(|A| \\cos \\theta\\).\nNow the dot product is that projection, multiplied by the magnitude of \\(\\vec{B}\\).\n\\[\\vec{A} \\cdot \\vec{B} = |A| |B| \\cos \\theta\\]\n\n\nWhat is \\(\\hat{n}\\)?\n\n\n\nAnswer\n\nIt is the unit normal vector, which has a length of one, and points in the direction perpendicular to the surface.\nNote that since \\(da\\) is the tiny amount of area we are considering\n\\[\\hat{n} da = d \\vec{a}\\]\n\n\nWhat is the difference between closed surface and open surface?\n\n\n\nAnswer\n\n\nOpen Surface - any surface for which it is possible to get from one side to the other without going through the surface\nClosed Surface - a surface that divides space into an “inside” and “outside”. Unit Normal Vector \\(\\hat{n}\\) always points outwards, away from the volume enclosed by the surface.\n\n\n\nWhat does \\(\\vec{E} \\cdot \\hat{n}\\) represent?\n\n\n\nAnswer\n\nThe component of the electric field vector that is perpendicular to the surface.\n\\[\\vec{E} \\cdot \\hat{n} = |\\vec{E}| \\cos \\theta\\]\n\n\nHow do you find the mass of a surface with varying density function \\(\\sigma(x, y)\\)?\n\n\n\nAnswer\n\nSince mass is density times volume, we can write:\n\\[Mass = \\sigma \\cdot Area\\]\n\\[Mass_S = \\Sigma_{i = 1}^{N} \\sigma_i \\cdot Area_i\\]\nIf we let Areas to become infinitesimally small \\(dA\\), we get \\[Mass = \\int_{S} \\sigma dA\\]\nThis is a surface intergal.\n\n\nWhat does \\(\\int_S \\vec{A} \\cdot \\hat{n} da\\) represent?\n\n\n\nAnswer\n\nIt represents the flux of a vector field.\nWhat’s a vector field?\nIt is magnitude and direction quantities distributed in space.\n\nScalar Field - something like temperature distribution in a room, where at each point theres a number\nVector Field - something like flow of fluid, there at every point it has a speed and direction\n\n\n\nWhat’s flux \\(\\Phi\\)?\n\n\n\nAnswer\n\nFlux \\(\\Phi\\) of a field over a surface is the amount of flow through that surface.\n\\[\\Phi = \\vec{A} \\cdot \\hat{n} \\times (Surface Area)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExpand To Learn About Right Hand Side\n\n\n\n\n\n\nWhat is the right hand side in words?\n\n\n\nAnswer\n\nThe total amount of enclosed charge normalized by the permittivity of free space.\n\n\nWhat is \\(\\epsilon_0\\) and why is it there?\n\n\n\nAnswer\n\nIt is called the permitivity of free space or “vacuum permitivity”.\n\\[\\epsilon_0 = 8.854 \\times 10^{-12} \\frac{F}{m}\\]\nWhen we say the permitivity of a material, when are referring to its reponse to an electric field. It is also the key parameter in determining the speed at which an electromagnetic wave propagates through that medium.\nHigh permitivity means it provides higher capacitance.\nIn Gauss’s Law, \\(\\epsilon_0\\) acts as a proportionality constant that relates electric flux to enclosed charge.\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nFive point charges are enclosed in a cylindrical surface \\(S\\). If the values of the charges are \\(q_1 = +3 nC\\), \\(q_2 = -2 nC\\), \\(q_3 = +2 nC\\), \\(q_4 = +4 nC\\), and \\(q_5 = -1 nC\\), find the total flux through \\(S\\).\n\n\n\nAnswer\n\n\\[\\sum_{i=1}^{5} q_i = 3 - 2 + 2 + 4 - 1 = 6 nC = 6 \\times 10^{-9} C\\]\n\\[\\Phi_E = \\frac{q_enc}{\\epsilon_0} = \\frac{6 \\times 10^{-9}C}{8.854 \\times 10^{-12} \\frac{C}{V \\cdot m}} = \\boxed{678 \\hspace{1mm} Vm}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExpand\n\nThe electric field produced by electric diverges from positive charge and converges upon negative charge.\n\\[\\vec{\\nabla} \\cdot \\vec{E} = \\frac{\\rho}{\\epsilon_0}\\]\n\n\n\n\n\n\nExpand To Learn About Left Hand Side\n\n\n\n\n\n\n\nWhat does the left hand side represent?\n\n\n\nAnswer\n\n\nThe tendency of electric field to flow away from a point in space - AKA the divergence.\n\n\nWhat is the difference between differential and integral form of Gauss’s Law?\n\n\n\nAnswer\n\n\nDifferential deals with individual points in space, whereareas integral deals with a closed surface.\n\n\nWhat is \\(\\vec{\\nabla}\\)?\n\n\n\nAnswer\n\n\nIt is called “del” or “nabla”. It tells you to take the derivative of what ever quantity comes after it.\n\\[\\vec{\\nabla} =\\hat{i} \\frac{\\partial}{\\partial x} + \\hat{j} \\frac{\\partial}{\\partial y} + \\hat{k} \\frac{\\partial}{\\partial z}\n\\]\nIt is an mathematical operator, which just means that it needs something to act on and cannot just appear by itself.\n\\(\\vec{\\nabla}\\) is gradient, \\(\\vec{\\nabla} \\cdot\\) is divergence, and \\(\\vec{\\nabla} \\times\\) is curl.\n\n\nWhat is \\(\\vec{\\nabla} \\cdot\\) specifically?\n\n\n\nExpand\n\nOliver Heaviside suggested the word “divergence” to describe the rate at which electric field flow outwards from a positive charge.\n\nsource - diverge from that point (positive charge for electric field)\nsink - converge to that point (negative charge for magnetic field)\n\n\n\n\n\n\n\n\n\n\n\n\nExpand To Learn About Right Hand Side\n\n\n\n\n\n\nWhat is the right hand side in words?\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nFive point charges are enclosed in a cylindrical surface \\(S\\). If the values of the charges are \\(q_1 = +3 nC\\), \\(q_2 = -2 nC\\), \\(q_3 = +2 nC\\), \\(q_4 = +4 nC\\), and \\(q_5 = -1 nC\\), find the total flux through \\(S\\).\n\n\n\nAnswer\n\n\\[\\sum_{i=1}^{5} q_i = 3 - 2 + 2 + 4 - 1 = 6 nC = 6 \\times 10^{-9} C\\]\n\\[\\Phi_E = \\frac{q_enc}{\\epsilon_0} = \\frac{6 \\times 10^{-9}C}{8.854 \\times 10^{-12} \\frac{C}{V \\cdot m}} = \\boxed{678 \\hspace{1mm} Vm}\\]"
  },
  {
    "objectID": "work/intro.html",
    "href": "work/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nThis is a book created from markdown and executable code.\nSee @knuth84 for additional discussion of literate programming."
  },
  {
    "objectID": "work/index.html",
    "href": "work/index.html",
    "title": "Preface",
    "section": "",
    "text": "Preface\nIf you are reading this, you may be interesed in seeing what is “Alex’s Notes”.\nThese notes are just things that I am documenting, that I wish could become a useful resource for my future students, either when I TA or become a professor.\nHere’s how to learn anything:\n\nWrite it out! (Document, Code along)\nEXPERIMENT and explore\nVisualize things you don’t understand\nAsk Questions\nAnswer Exercise and Problems (stretch your knowledge)\nShare with like-minded individuals"
  },
  {
    "objectID": "work/courses/dls.html",
    "href": "work/courses/dls.html",
    "title": "Deep Learning Systems",
    "section": "",
    "text": "In this set of notes, we will create a minimal version of PyTorch / Tensorflow from scratch, of what I call “PyStickOnFire”.\n\n\nThe (Supervised) Machine learning idea: we take a bunch of labeled data, feed them to a machine learning algorithm, and it outputs a “program” that solves the task.\n\\[\\text{Training Dataset X} \\rightarrow \\boxed{\\text{Machine Learning Algorithm}} \\rightarrow \\text{Model }h\\]\nWe will focus on what the machine learning algorithm box contains. In general, it consists of three things:\n\nThe hypothesis class (the structure of \\(h\\) in terms of a set of parameters)\nThe loss function (specifies how good a given hypothesis is)\nAn optimization method (the way to minimize the loss function)\n\nAll alogrithms in machine learning fit in this structure. Let’s look at softmax regression to illustrate these three basic components.\n\n\nConsider a k-class classification setting, where we have\n\ntraining data: \\[x^{(i)} \\in \\mathbb{R}^{n}, y^{(i)} \\in \\{1, \\dots, k \\} \\text{ for } i = 1, \\dots, m\\]\n\n\\(n =\\) dimensionality of input data\n\\(k =\\) number of different classes / labels\n\\(m =\\) number of data points in the training data\n\n\nwhere the training data are vectors that looks like \\[X = \\{ \\begin{bmatrix} x^{(1)}_1 \\\\ x^{(1)}_2 \\\\ \\vdots \\\\ x^{(1)}_n \\end{bmatrix} , \\dots, \\begin{bmatrix} x^{(m)}_1 \\\\ x^{(m)}_2 \\\\ \\vdots \\\\ x^{(m)}_n \\end{bmatrix} \\}\\] and the labels are just a set of scalars of size \\(k\\).\n\n\n\nThe hypothesis function is a mapping from one input to one output. (Duhh… just like every other function there is). \\[h: \\mathbb{R^n} \\rightarrow \\mathbb{R^k}\\] \\[h(x) = \\begin{bmatrix} h_1(x) \\\\ h_2(x) \\\\ \\vdots \\\\ h_k(x)\\end{bmatrix}\\]\nSo what really is \\(h_i(x)\\)? It is the hypothesis, the “belief”, the probability of how likely \\(x\\) maps to class \\(i\\).\nA linear hypothesis function uses matrix multiplication, or some other linear way, for this transformation:\n\\[h_\\theta(x) = \\theta^T x\\]\nfor parameters \\(\\theta \\in \\mathbb{R^{n \\times k}}\\) (\\(n\\) rows and \\(k\\) columns, so transpose becomes \\(k \\times n\\), and \\(x \\in \\mathbb{R^{n \\times 1}}\\), so multiplication will work). Now we say \\(h_\\theta\\) because \\(\\theta\\) is the parameters.\nNotice how so far we only have one input and one output, \\(h\\) is only working on one instance of the training set. However, in order to implement these operations efficiently in the future, we shall use the matrix batch notation.\n\\[X \\in \\mathbb{R^{m \\times n}} = \\begin{bmatrix} -x^{(1)^{T}}- \\\\ -x^{(2)^{T}}- \\\\ \\vdots \\\\ -x^{(m)^{T}}- \\end{bmatrix}\\]\n\\[y \\in \\{ 1, \\dots, k \\}^m = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)}  \\end{bmatrix}\\]\n\\[h_\\theta(X) = \\begin{bmatrix} -h_\\theta(x^{(1)})^{T}- \\\\ -h_\\theta(x^{(2)})^{T}- \\\\ \\vdots \\\\ -h_\\theta(x^{(m)})^{T}- \\end{bmatrix} = \\begin{bmatrix} -x^{(1)^{T}} \\theta- \\\\ -x^{(2)^{T}} \\theta- \\\\ \\vdots \\\\ -x^{(m)^{T}} \\theta- \\end{bmatrix} = X\\theta\\]\n\n\\(n =\\) dimensionality of input data\n\\(k =\\) number of different classes / labels\n\\(m =\\) number of data points in the training data\n\nEach row is for a data point, the first example is in first row (originally a column vector, now we transposed it to row vector), and the second example is in second row, and so on… Note that this is not merely a notation change, but rather how to implement them more efficiently in code later on.\n\n\n\nHow are we going to evaluate the quality of our predictions?\nClassification Error\n\\[l_{err}(h(x),y) = \\begin{cases} 0, & \\text{if } argmax_i h_i(x) = y \\\\ 1, & \\text{otherwise} \\end{cases}\\]\nThe error is not differentiable, so it is not good for optimization.\nA better choice: Cross-Entropy Loss or Softmax\nThe idea is that we want to map our outputs into being actual probabilities\n\\[h_i(x) \\rightarrow prob[label == i]\\]\nProbability has to be positive and sum to 1. In order to ensure \\(h_i(x)\\) is positive, we can exponentiate it. In order to ensure all \\(h_i(x)'s\\) to sum to 1, we need to normalize them.\n\\[prob[label == i] = normalize(\\exp(h(x)))= \\frac{\\exp(h_i(x))}{\\sum_{j = 1}^{k} \\exp(h_j(x))} = softmax(h(x))\\]\nThis is called the softmax operation, a mapping between scalar values and a probability distribution.\nSo now we have a probability, We need some way of quantifying whether the vector of probabilities \\(softmax(h(x))\\) is good or not. We want \\(prob[label == y]\\) to be high, as large as possible, so the loss function idea can be minimizing the negative of this probability (double negative makes a positive!).\n\\[l_{cross-entropy} (h(x), y) = - prob[label = y]\\]\nBecause minimizing probabilities is not numerically good: Probabilities are bounded between \\(0\\) and \\(1\\), so their gradients near \\(0\\) can become tiny (vanishing gradients). Logs transform that range \\((0,1)\\) into \\((−\\infty,0)\\), making the loss surface smoother and the gradients more useful. So we take the log of it\n\\[l_{ce} (h(x), y) = - log(prob[label = y]) = -h_y(x) + log \\sum_{j=1}^{k} exp(h_j(x))\\]\nThis is commonly known as the negative log loss or cross-entropy loss. This is also a case of convex optimization.\n\n\n\nHow do we find good values for \\(\\theta\\)?\nThis element we will spend the most time to cover because we not only what to know what the optimization is, but how we are optimizing it.\nThe following problem is the problem that almost all machine algorithms are solving. Here is the problem,\n\\[\n\\min_{\\theta} \\frac{1}{m} \\sum_{i=1}^{m} l(h_\\theta(x^{(i)}), y^{(i)})\n\\]\nWe are searching over all possible values of \\(\\theta\\), the one that minimizes the average loss. For example, here’s softmax regression,\n\\[\n\\min_{\\theta} f(\\theta) = \\min_{\\theta} \\frac{1}{m} \\sum_{i=1}^{m} l_{ce}(\\theta^T x^{(i)}, y^{(i)})\n\\]\nNow we know the “what”, but, how do we find that? How do we solve \\(\\min_{\\theta} f(\\theta) ?\\)\n\n\nFor our \\(f(\\theta)\\) (the function that we are trying to minimize), remember, this function takes the parameter (which is of dimension n examples by k output classes) and outputs a loss scalar, in other words \\[f: \\mathbb{R^{n \\times k}} \\rightarrow \\mathbb{R}\\]\n\\[f(\\theta) \\in \\mathbb{R}\\]\nRemember that the gradient is a multidimensional derivative that has a direction, which points to the direction of sharpest increase (locally). The gradient operator can only act on a scalar and return a vector.\nHere is the definition of the gradient in our case,\n\\[\\nabla_\\theta f(\\theta) = \\begin{bmatrix}\n\\frac{\\partial f}{\\partial \\theta_{11}} \\frac{\\partial f}{\\partial \\theta_{12}} \\dots \\frac{\\partial f}{\\partial \\theta_{1k}} \\\\\n\\frac{\\partial f}{\\partial \\theta_{21}} \\frac{\\partial f}{\\partial \\theta_{22}}  \\dots \\frac{\\partial f}{\\partial \\theta_{2k}} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial \\theta_{n1}} \\frac{\\partial f}{\\partial \\theta_{n2}}  \\dots \\frac{\\partial f}{\\partial \\theta_{nk}}\n\\end{bmatrix} \\in \\mathbb{R^{n \\times k}}\\]\nThe derivative of a function is the slope of the function, change in \\(y\\) over change in \\(x\\).\n\n\n\nIf the gradient points in the direction of maximum increase, to minimize a function, we can repeatedly step in the opposite direction. In other words,\n\\[\\theta = \\theta - \\alpha \\nabla_\\theta f(\\theta)\\]\nwhere \\(\\alpha\\) is called the learning rate or step size. Note that the learning rate must be positive for the stepping direction to be in the negative direction from the gradient. This basic idea powers all deep learning. It is really hard to encapsulate how impactful this one line of math has been.\nThe choice of the step size \\(\\alpha\\) is really really really important. Too small slows down progress, but too big will overshoot.\n\n\n\nWe split up the dataset into minibatches, which are subsets of data of size \\(B\\).\nWe repeat the process of sampling minibatches and taking steps to update \\(\\theta\\).\n\nSample: \\(X \\in \\mathbb{R^{B \\times n}}, y \\in \\{ 1, \\dots, k\\}^B\\)\nUpdate: \\(\\theta = \\theta - \\frac{\\alpha}{B} \\sum_{i=1}^{B} \\nabla_\\theta l(h_\\theta(x^{(i)}), y^{(i)})\\)\n\n\n\n\nIn order to calculate the gradient of \\(f(\\theta)\\), which is essentially the sum of gradients,\n\\[\\nabla_\\theta \\frac{1}{m} \\sum_{i=1}^{m} l(h_\\theta(x^{(i)}), y^{(i)}) =  \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta l(h_\\theta(x^{(i)}), y^{(i)})\\]\nWe have to calculate the gradient \\(m\\) times, which is very expensive. Can we reduce the number of times we take gradient? Yes, and that’s what we actually do in practice.\nAs an example, how do we compute the gradient for softmax objective? We can do it by hand, but it is cumbersome. You can use something like chain rule. We want derivative of a vector with respect to a matrix……We need some more general and generic way to take derivatives. What can we do?\nIn practice, we just specify the hypothesis function and the loss function, and use Automatic Differentiation. But how?\nWe can either do it through the “right” way, use matrix differential calculus, jacobians, kronecker products, and vectorization. Or we could take a shortcut (what everyone actually does): We pretend everything is scalar, use typical chain rule, and then transpose/rearrange outputs to make sizes work, and then check your answers numerically.\n\\[\\frac{\\partial}{\\partial \\theta} l_{ce} (\\theta^T x, y)= \\frac{\\partial l_{ce} (\\theta^T x, y)}{\\partial \\theta^T x} \\cdot \\frac{\\partial \\theta^T x}{\\partial \\theta}\\]"
  },
  {
    "objectID": "work/courses/dls.html#chapter-1-machine-learning-refresher",
    "href": "work/courses/dls.html#chapter-1-machine-learning-refresher",
    "title": "Deep Learning Systems",
    "section": "",
    "text": "The (Supervised) Machine learning idea: we take a bunch of labeled data, feed them to a machine learning algorithm, and it outputs a “program” that solves the task.\n\\[\\text{Training Dataset X} \\rightarrow \\boxed{\\text{Machine Learning Algorithm}} \\rightarrow \\text{Model }h\\]\nWe will focus on what the machine learning algorithm box contains. In general, it consists of three things:\n\nThe hypothesis class (the structure of \\(h\\) in terms of a set of parameters)\nThe loss function (specifies how good a given hypothesis is)\nAn optimization method (the way to minimize the loss function)\n\nAll alogrithms in machine learning fit in this structure. Let’s look at softmax regression to illustrate these three basic components.\n\n\nConsider a k-class classification setting, where we have\n\ntraining data: \\[x^{(i)} \\in \\mathbb{R}^{n}, y^{(i)} \\in \\{1, \\dots, k \\} \\text{ for } i = 1, \\dots, m\\]\n\n\\(n =\\) dimensionality of input data\n\\(k =\\) number of different classes / labels\n\\(m =\\) number of data points in the training data\n\n\nwhere the training data are vectors that looks like \\[X = \\{ \\begin{bmatrix} x^{(1)}_1 \\\\ x^{(1)}_2 \\\\ \\vdots \\\\ x^{(1)}_n \\end{bmatrix} , \\dots, \\begin{bmatrix} x^{(m)}_1 \\\\ x^{(m)}_2 \\\\ \\vdots \\\\ x^{(m)}_n \\end{bmatrix} \\}\\] and the labels are just a set of scalars of size \\(k\\).\n\n\n\nThe hypothesis function is a mapping from one input to one output. (Duhh… just like every other function there is). \\[h: \\mathbb{R^n} \\rightarrow \\mathbb{R^k}\\] \\[h(x) = \\begin{bmatrix} h_1(x) \\\\ h_2(x) \\\\ \\vdots \\\\ h_k(x)\\end{bmatrix}\\]\nSo what really is \\(h_i(x)\\)? It is the hypothesis, the “belief”, the probability of how likely \\(x\\) maps to class \\(i\\).\nA linear hypothesis function uses matrix multiplication, or some other linear way, for this transformation:\n\\[h_\\theta(x) = \\theta^T x\\]\nfor parameters \\(\\theta \\in \\mathbb{R^{n \\times k}}\\) (\\(n\\) rows and \\(k\\) columns, so transpose becomes \\(k \\times n\\), and \\(x \\in \\mathbb{R^{n \\times 1}}\\), so multiplication will work). Now we say \\(h_\\theta\\) because \\(\\theta\\) is the parameters.\nNotice how so far we only have one input and one output, \\(h\\) is only working on one instance of the training set. However, in order to implement these operations efficiently in the future, we shall use the matrix batch notation.\n\\[X \\in \\mathbb{R^{m \\times n}} = \\begin{bmatrix} -x^{(1)^{T}}- \\\\ -x^{(2)^{T}}- \\\\ \\vdots \\\\ -x^{(m)^{T}}- \\end{bmatrix}\\]\n\\[y \\in \\{ 1, \\dots, k \\}^m = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)}  \\end{bmatrix}\\]\n\\[h_\\theta(X) = \\begin{bmatrix} -h_\\theta(x^{(1)})^{T}- \\\\ -h_\\theta(x^{(2)})^{T}- \\\\ \\vdots \\\\ -h_\\theta(x^{(m)})^{T}- \\end{bmatrix} = \\begin{bmatrix} -x^{(1)^{T}} \\theta- \\\\ -x^{(2)^{T}} \\theta- \\\\ \\vdots \\\\ -x^{(m)^{T}} \\theta- \\end{bmatrix} = X\\theta\\]\n\n\\(n =\\) dimensionality of input data\n\\(k =\\) number of different classes / labels\n\\(m =\\) number of data points in the training data\n\nEach row is for a data point, the first example is in first row (originally a column vector, now we transposed it to row vector), and the second example is in second row, and so on… Note that this is not merely a notation change, but rather how to implement them more efficiently in code later on.\n\n\n\nHow are we going to evaluate the quality of our predictions?\nClassification Error\n\\[l_{err}(h(x),y) = \\begin{cases} 0, & \\text{if } argmax_i h_i(x) = y \\\\ 1, & \\text{otherwise} \\end{cases}\\]\nThe error is not differentiable, so it is not good for optimization.\nA better choice: Cross-Entropy Loss or Softmax\nThe idea is that we want to map our outputs into being actual probabilities\n\\[h_i(x) \\rightarrow prob[label == i]\\]\nProbability has to be positive and sum to 1. In order to ensure \\(h_i(x)\\) is positive, we can exponentiate it. In order to ensure all \\(h_i(x)'s\\) to sum to 1, we need to normalize them.\n\\[prob[label == i] = normalize(\\exp(h(x)))= \\frac{\\exp(h_i(x))}{\\sum_{j = 1}^{k} \\exp(h_j(x))} = softmax(h(x))\\]\nThis is called the softmax operation, a mapping between scalar values and a probability distribution.\nSo now we have a probability, We need some way of quantifying whether the vector of probabilities \\(softmax(h(x))\\) is good or not. We want \\(prob[label == y]\\) to be high, as large as possible, so the loss function idea can be minimizing the negative of this probability (double negative makes a positive!).\n\\[l_{cross-entropy} (h(x), y) = - prob[label = y]\\]\nBecause minimizing probabilities is not numerically good: Probabilities are bounded between \\(0\\) and \\(1\\), so their gradients near \\(0\\) can become tiny (vanishing gradients). Logs transform that range \\((0,1)\\) into \\((−\\infty,0)\\), making the loss surface smoother and the gradients more useful. So we take the log of it\n\\[l_{ce} (h(x), y) = - log(prob[label = y]) = -h_y(x) + log \\sum_{j=1}^{k} exp(h_j(x))\\]\nThis is commonly known as the negative log loss or cross-entropy loss. This is also a case of convex optimization.\n\n\n\nHow do we find good values for \\(\\theta\\)?\nThis element we will spend the most time to cover because we not only what to know what the optimization is, but how we are optimizing it.\nThe following problem is the problem that almost all machine algorithms are solving. Here is the problem,\n\\[\n\\min_{\\theta} \\frac{1}{m} \\sum_{i=1}^{m} l(h_\\theta(x^{(i)}), y^{(i)})\n\\]\nWe are searching over all possible values of \\(\\theta\\), the one that minimizes the average loss. For example, here’s softmax regression,\n\\[\n\\min_{\\theta} f(\\theta) = \\min_{\\theta} \\frac{1}{m} \\sum_{i=1}^{m} l_{ce}(\\theta^T x^{(i)}, y^{(i)})\n\\]\nNow we know the “what”, but, how do we find that? How do we solve \\(\\min_{\\theta} f(\\theta) ?\\)\n\n\nFor our \\(f(\\theta)\\) (the function that we are trying to minimize), remember, this function takes the parameter (which is of dimension n examples by k output classes) and outputs a loss scalar, in other words \\[f: \\mathbb{R^{n \\times k}} \\rightarrow \\mathbb{R}\\]\n\\[f(\\theta) \\in \\mathbb{R}\\]\nRemember that the gradient is a multidimensional derivative that has a direction, which points to the direction of sharpest increase (locally). The gradient operator can only act on a scalar and return a vector.\nHere is the definition of the gradient in our case,\n\\[\\nabla_\\theta f(\\theta) = \\begin{bmatrix}\n\\frac{\\partial f}{\\partial \\theta_{11}} \\frac{\\partial f}{\\partial \\theta_{12}} \\dots \\frac{\\partial f}{\\partial \\theta_{1k}} \\\\\n\\frac{\\partial f}{\\partial \\theta_{21}} \\frac{\\partial f}{\\partial \\theta_{22}}  \\dots \\frac{\\partial f}{\\partial \\theta_{2k}} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial \\theta_{n1}} \\frac{\\partial f}{\\partial \\theta_{n2}}  \\dots \\frac{\\partial f}{\\partial \\theta_{nk}}\n\\end{bmatrix} \\in \\mathbb{R^{n \\times k}}\\]\nThe derivative of a function is the slope of the function, change in \\(y\\) over change in \\(x\\).\n\n\n\nIf the gradient points in the direction of maximum increase, to minimize a function, we can repeatedly step in the opposite direction. In other words,\n\\[\\theta = \\theta - \\alpha \\nabla_\\theta f(\\theta)\\]\nwhere \\(\\alpha\\) is called the learning rate or step size. Note that the learning rate must be positive for the stepping direction to be in the negative direction from the gradient. This basic idea powers all deep learning. It is really hard to encapsulate how impactful this one line of math has been.\nThe choice of the step size \\(\\alpha\\) is really really really important. Too small slows down progress, but too big will overshoot.\n\n\n\nWe split up the dataset into minibatches, which are subsets of data of size \\(B\\).\nWe repeat the process of sampling minibatches and taking steps to update \\(\\theta\\).\n\nSample: \\(X \\in \\mathbb{R^{B \\times n}}, y \\in \\{ 1, \\dots, k\\}^B\\)\nUpdate: \\(\\theta = \\theta - \\frac{\\alpha}{B} \\sum_{i=1}^{B} \\nabla_\\theta l(h_\\theta(x^{(i)}), y^{(i)})\\)\n\n\n\n\nIn order to calculate the gradient of \\(f(\\theta)\\), which is essentially the sum of gradients,\n\\[\\nabla_\\theta \\frac{1}{m} \\sum_{i=1}^{m} l(h_\\theta(x^{(i)}), y^{(i)}) =  \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta l(h_\\theta(x^{(i)}), y^{(i)})\\]\nWe have to calculate the gradient \\(m\\) times, which is very expensive. Can we reduce the number of times we take gradient? Yes, and that’s what we actually do in practice.\nAs an example, how do we compute the gradient for softmax objective? We can do it by hand, but it is cumbersome. You can use something like chain rule. We want derivative of a vector with respect to a matrix……We need some more general and generic way to take derivatives. What can we do?\nIn practice, we just specify the hypothesis function and the loss function, and use Automatic Differentiation. But how?\nWe can either do it through the “right” way, use matrix differential calculus, jacobians, kronecker products, and vectorization. Or we could take a shortcut (what everyone actually does): We pretend everything is scalar, use typical chain rule, and then transpose/rearrange outputs to make sizes work, and then check your answers numerically.\n\\[\\frac{\\partial}{\\partial \\theta} l_{ce} (\\theta^T x, y)= \\frac{\\partial l_{ce} (\\theta^T x, y)}{\\partial \\theta^T x} \\cdot \\frac{\\partial \\theta^T x}{\\partial \\theta}\\]"
  },
  {
    "objectID": "work/courses/optics.html",
    "href": "work/courses/optics.html",
    "title": "Optics",
    "section": "",
    "text": "The wave equation is given by\n\\[\\psi(x,t) = \\frac{3}{[10(x - vt)^2 + 1]}\\]\nShow, using brute force, that this is a solution to the one dimensional differential wave equation.\nGreat! Let’s start with what is a wave.\nDef. A classical traveling wave is a self-sustaining disturbance \\(\\psi\\) of a medium, and the disturbance \\(\\psi\\) moves through space transporting energy and momentum.\nEverything is waves.\nSound! A type of longitudinal wave, where the displacement vector points parallel to the direction of motion.\nGuitar string! A type of transverse wave, where the displacement vector points perpendicular to the direction of motion.\nA wave is not a stream of particles! Because the individual atoms stay in equilibrium, but only the disturbance advances through them. Leonardo da Vinci was one of the first person to realize waves does not transport the medium through which it travels.\nImagine disturbance \\(\\psi\\) moves in positive direction \\(x\\) with constant velocity \\(v\\).\n\\[\\psi = f(x,t)\\]\nWhat is \\(f(x,0)\\)? it is the shape (aka the profile) of \\(\\psi\\) at \\(t=0\\). For example, try visualizing \\(f(x) = e^{-ax^2}\\), you’ll see that it is a gaussian function. Setting \\(t=0\\) is taking a snapshot of the pulse as it travels by.\nIn order to understand this better, let’s ignore \\(t\\) by introducing a coordinate system \\(S^{'}\\) that travels with the pilse at the speed \\(v\\). As we move with \\(S^{'}\\), the wave looks stationary! So\n\\[\\psi = f \\left( x^{'} \\right)\\]\nwhere \\(x^{'} = x - vt\\), because after time \\(t\\) the same point on \\(\\psi\\) moved a distance of \\(vt\\).\n\n\n\\[\\psi(x,t) = f(x - vt)\\]\nJean Le Rond d’Alembert was the one that brought partial differential equations to physics and formulated the differential wave equation."
  },
  {
    "objectID": "work/courses/optics.html#q1-one-dimensional-wave-equation",
    "href": "work/courses/optics.html#q1-one-dimensional-wave-equation",
    "title": "Optics",
    "section": "",
    "text": "The wave equation is given by\n\\[\\psi(x,t) = \\frac{3}{[10(x - vt)^2 + 1]}\\]\nShow, using brute force, that this is a solution to the one dimensional differential wave equation.\nGreat! Let’s start with what is a wave.\nDef. A classical traveling wave is a self-sustaining disturbance \\(\\psi\\) of a medium, and the disturbance \\(\\psi\\) moves through space transporting energy and momentum.\nEverything is waves.\nSound! A type of longitudinal wave, where the displacement vector points parallel to the direction of motion.\nGuitar string! A type of transverse wave, where the displacement vector points perpendicular to the direction of motion.\nA wave is not a stream of particles! Because the individual atoms stay in equilibrium, but only the disturbance advances through them. Leonardo da Vinci was one of the first person to realize waves does not transport the medium through which it travels.\nImagine disturbance \\(\\psi\\) moves in positive direction \\(x\\) with constant velocity \\(v\\).\n\\[\\psi = f(x,t)\\]\nWhat is \\(f(x,0)\\)? it is the shape (aka the profile) of \\(\\psi\\) at \\(t=0\\). For example, try visualizing \\(f(x) = e^{-ax^2}\\), you’ll see that it is a gaussian function. Setting \\(t=0\\) is taking a snapshot of the pulse as it travels by.\nIn order to understand this better, let’s ignore \\(t\\) by introducing a coordinate system \\(S^{'}\\) that travels with the pilse at the speed \\(v\\). As we move with \\(S^{'}\\), the wave looks stationary! So\n\\[\\psi = f \\left( x^{'} \\right)\\]\nwhere \\(x^{'} = x - vt\\), because after time \\(t\\) the same point on \\(\\psi\\) moved a distance of \\(vt\\).\n\n\n\\[\\psi(x,t) = f(x - vt)\\]\nJean Le Rond d’Alembert was the one that brought partial differential equations to physics and formulated the differential wave equation."
  },
  {
    "objectID": "work/courses/fastai.html",
    "href": "work/courses/fastai.html",
    "title": "Practical Deep Learning (fast.ai)",
    "section": "",
    "text": "Source: https://course.fast.ai/\n\n\nDaniel 深度碎片 on forums.fast.ai has been kind enough to create summaries of each lesson in the form of a list of questions. These summaries can be used to preview a lesson or refresh your memory afterward.\n\n\n\nCan there be substantial new content given we have already 4 versions and a book?\n\n\n\n\n\nHow many channels are available to read the book? (physical, GitHub, Colab, and others)\n\n\n\n\n\nAre there interesting materials/stories covered by the book but not the lecture?\nWhere can you find questionnaires and quizzes of the lectures?\n\n\n\n\n\nWhere can you get more quizzes of fastai and memorize them forever?\n\n\n\n\n\nHow to make the most out of fastai forum?\n\n\n\n\n\n\n\n\nWill we learn to put a model in production today?\n\n\n\n\n\nWhat is the first step before building a model?\n\n\n\n\n\nDo you want to navigate the notebook with a TOC?\nHow about collapsible sections?\nHow about moving between start and end of sections fast?\nHow to install Jupyter extensions?\n\n\n\n\n\nWhy use ggd rather than Bing for searching and downloading images?\nHow to clean/remove broken images?\n\n\n\n\n\nHow to get basic info, source code, full docs on fastai code quickly?\n\n\n\n\n\nHow can you specify the resize options to your data?\nWhy should we always use RandomResizedCrop and aug_transforms together?\nHow do RandomResizedCrop and aug_transforms differ?\n\n\n\n\n\nWhen resized, are we making many copies of the image?\n\n\n\n\n\nHow many epochs do we usually go when using RandomResizedCrop and aug_transforms?\n\n\n\n\n\nHow to create a confusion matrix on your model performance?\nWhen to use a confusion matrix? (category-level practice)\nHow to interpret a confusion matrix?\nWhat is the most obvious thing it tells us?\nHow hard is it to tell grizzly and black bears apart?\n\n\n\n\n\nDoes plot_top_losses give us the images with the highest losses?\nAre those images ones the model made confidently wrong predictions? (practice)\nDo those images include ones that the model made correct predictions unconfidently?\nWhat does looking at those high loss images help with? (expert examination or simple data cleaning)\n\n\n\n\n\nHow to display and make cleaning choices on each of those top loss images in each data folder? (practice)\nWithout expert knowledge on telling apart grizzly and black bears, we can at least clean images which mess up teddy bears.\n\n\n\n\n\nHow can training the model help us see problems in the dataset? (practice)\nWon’t we have more ideas to improve the dataset once we spot the problems?\n\n\n\n\n\nHow to use GPU RAM locally without much trouble?\n\n\n\n\n\nWhat is the preferred way of lecture watching and coding by the majority of students?\n\n\n\n\n\n\n\n\nIs GitHub Desktop a less cool but easier and more robust way to version control than git?\n\n\n\n\n\nHow to set up a terminal for Windows?\nWhy does Jeremy prefer Windows over Mac?\n\n\n\n\n\nGo to huggingface.co/spaces and create a new space\n\n\n\n\n\nHow to use git to download your space folder?\nHow to open VSCode to add an app.py file?\nHow to use VSCode to push your space folder up to Hugging Face Spaces online?\nThen go back to your space on Hugging Face to see the app running\n\n\n\n\n\nWhere is the model we are going to train and download from Kaggle notebook?\nHow to export your model after training it on Kaggle?\nWhere do you download the model?\nHow to open a folder in terminal? open .\nMake sure the model is downloaded into its own Hugging Face Space folder\n\n\n\n\n\nHow to load the downloaded model to make predictions?\nHow to make predictions with the loaded model?\nHow to export selected cells of a Jupyter notebook into a Python file?\nHow to see how long a code runs in a Jupyter cell?\n\n\n\n\n\nHow to prepare your prediction result into a form Gradio prefers? (code)\nHow to build a Gradio interface for your model?\nHow to launch your app with the model locally?\n(Not in video: run the code on Kaggle in cloud)\n\n\n\n\n\nMake sure to create a new space first (e.g., testing)\nHow to turn the notebook into a Python script?\nHow to push the folder up to GitHub and run app in cloud?\n(Not in Video: if stuck, check out Tanishq’s tutorial – shooting)\n\n\n\n\n\nHow many epochs are ideal for fine-tuning?\nHow to save model from Colab?\n\n\n\n\n\nHow to download github/fastai/fastsetup using git?\ngit clone https://github.com/fastai/fastsetup.git\nHow to download and install mamba?\n./setup_conda.sh\n(Not in Video: problem of running ./setup_conda.sh)\nHow to download and install fastai?\nmamba install -c fastchan fastai\nHow to install nbdev?\nmamba install -c fastchan nbdev\nHow to start using Jupyter Notebook?\njupyter notebook --no-browser\n(Not in Video: other problem related to Xcode)"
  },
  {
    "objectID": "work/courses/fastai.html#lesson-2",
    "href": "work/courses/fastai.html#lesson-2",
    "title": "Practical Deep Learning (fast.ai)",
    "section": "",
    "text": "Daniel 深度碎片 on forums.fast.ai has been kind enough to create summaries of each lesson in the form of a list of questions. These summaries can be used to preview a lesson or refresh your memory afterward.\n\n\n\nCan there be substantial new content given we have already 4 versions and a book?\n\n\n\n\n\nHow many channels are available to read the book? (physical, GitHub, Colab, and others)\n\n\n\n\n\nAre there interesting materials/stories covered by the book but not the lecture?\nWhere can you find questionnaires and quizzes of the lectures?\n\n\n\n\n\nWhere can you get more quizzes of fastai and memorize them forever?\n\n\n\n\n\nHow to make the most out of fastai forum?\n\n\n\n\n\n\n\n\nWill we learn to put a model in production today?\n\n\n\n\n\nWhat is the first step before building a model?\n\n\n\n\n\nDo you want to navigate the notebook with a TOC?\nHow about collapsible sections?\nHow about moving between start and end of sections fast?\nHow to install Jupyter extensions?\n\n\n\n\n\nWhy use ggd rather than Bing for searching and downloading images?\nHow to clean/remove broken images?\n\n\n\n\n\nHow to get basic info, source code, full docs on fastai code quickly?\n\n\n\n\n\nHow can you specify the resize options to your data?\nWhy should we always use RandomResizedCrop and aug_transforms together?\nHow do RandomResizedCrop and aug_transforms differ?\n\n\n\n\n\nWhen resized, are we making many copies of the image?\n\n\n\n\n\nHow many epochs do we usually go when using RandomResizedCrop and aug_transforms?\n\n\n\n\n\nHow to create a confusion matrix on your model performance?\nWhen to use a confusion matrix? (category-level practice)\nHow to interpret a confusion matrix?\nWhat is the most obvious thing it tells us?\nHow hard is it to tell grizzly and black bears apart?\n\n\n\n\n\nDoes plot_top_losses give us the images with the highest losses?\nAre those images ones the model made confidently wrong predictions? (practice)\nDo those images include ones that the model made correct predictions unconfidently?\nWhat does looking at those high loss images help with? (expert examination or simple data cleaning)\n\n\n\n\n\nHow to display and make cleaning choices on each of those top loss images in each data folder? (practice)\nWithout expert knowledge on telling apart grizzly and black bears, we can at least clean images which mess up teddy bears.\n\n\n\n\n\nHow can training the model help us see problems in the dataset? (practice)\nWon’t we have more ideas to improve the dataset once we spot the problems?\n\n\n\n\n\nHow to use GPU RAM locally without much trouble?\n\n\n\n\n\nWhat is the preferred way of lecture watching and coding by the majority of students?\n\n\n\n\n\n\n\n\nIs GitHub Desktop a less cool but easier and more robust way to version control than git?\n\n\n\n\n\nHow to set up a terminal for Windows?\nWhy does Jeremy prefer Windows over Mac?\n\n\n\n\n\nGo to huggingface.co/spaces and create a new space\n\n\n\n\n\nHow to use git to download your space folder?\nHow to open VSCode to add an app.py file?\nHow to use VSCode to push your space folder up to Hugging Face Spaces online?\nThen go back to your space on Hugging Face to see the app running\n\n\n\n\n\nWhere is the model we are going to train and download from Kaggle notebook?\nHow to export your model after training it on Kaggle?\nWhere do you download the model?\nHow to open a folder in terminal? open .\nMake sure the model is downloaded into its own Hugging Face Space folder\n\n\n\n\n\nHow to load the downloaded model to make predictions?\nHow to make predictions with the loaded model?\nHow to export selected cells of a Jupyter notebook into a Python file?\nHow to see how long a code runs in a Jupyter cell?\n\n\n\n\n\nHow to prepare your prediction result into a form Gradio prefers? (code)\nHow to build a Gradio interface for your model?\nHow to launch your app with the model locally?\n(Not in video: run the code on Kaggle in cloud)\n\n\n\n\n\nMake sure to create a new space first (e.g., testing)\nHow to turn the notebook into a Python script?\nHow to push the folder up to GitHub and run app in cloud?\n(Not in Video: if stuck, check out Tanishq’s tutorial – shooting)\n\n\n\n\n\nHow many epochs are ideal for fine-tuning?\nHow to save model from Colab?\n\n\n\n\n\nHow to download github/fastai/fastsetup using git?\ngit clone https://github.com/fastai/fastsetup.git\nHow to download and install mamba?\n./setup_conda.sh\n(Not in Video: problem of running ./setup_conda.sh)\nHow to download and install fastai?\nmamba install -c fastchan fastai\nHow to install nbdev?\nmamba install -c fastchan nbdev\nHow to start using Jupyter Notebook?\njupyter notebook --no-browser\n(Not in Video: other problem related to Xcode)"
  },
  {
    "objectID": "work/courses/eft.html",
    "href": "work/courses/eft.html",
    "title": "Electromagnetic Field Theory",
    "section": "",
    "text": "Phasors\nPhasor Arithmetic\nScalars & Vectors\n\nA time-harmonic fuunction can be written as\n\\[y(t) = A \\cos(\\omega t + \\theta)\\]\nThe math becomes easier if we simplify it with\n\\[e^{j \\theta} = \\cos(\\theta) + j \\sin(\\theta) \\tag{Euler's Formula}\\] \\[y(t) = Re[ A e^{j(\\omega t + \\theta)} ]= Re[ A e^{j\\omega t} e^{j\\theta} ]\\]"
  },
  {
    "objectID": "work/courses/eft.html#mathematical-preliminaries",
    "href": "work/courses/eft.html#mathematical-preliminaries",
    "title": "Electromagnetic Field Theory",
    "section": "",
    "text": "Phasors\nPhasor Arithmetic\nScalars & Vectors\n\nA time-harmonic fuunction can be written as\n\\[y(t) = A \\cos(\\omega t + \\theta)\\]\nThe math becomes easier if we simplify it with\n\\[e^{j \\theta} = \\cos(\\theta) + j \\sin(\\theta) \\tag{Euler's Formula}\\] \\[y(t) = Re[ A e^{j(\\omega t + \\theta)} ]= Re[ A e^{j\\omega t} e^{j\\theta} ]\\]"
  },
  {
    "objectID": "work/courses/Applied_Electromagnetics.html",
    "href": "work/courses/Applied_Electromagnetics.html",
    "title": "Applied Electromagnetics",
    "section": "",
    "text": "Maxwell’s Equations predict waves\nDerivation and solution of the wave equation\n\nIn source-free media, \\(\\vec{J} = 0\\) and \\(\\rho_V = 0\\), maxwell’s equations in the frequency-domain become\nCurl Equations\n\\[\\nabla \\times \\vec{E} = -j\\omega \\vec{B}\\] \\[\\nabla \\times \\vec{H} = -j\\omega \\vec{D}\\]\nDivergence Equations\n\\[\\nabla \\cdot \\vec{D} = 0\\] \\[\\nabla \\cdot \\vec{B} = 0\\]\nConstitutive Relations\n\\[\\vec{D} = \\epsilon \\vec{E}\\] \\[\\vec{B} = \\epsilon \\vec{H}\\]\nSubstituting constitutive relations into the curl equations, we get:\n\\[\\nabla \\times \\vec{E} = -j \\omega \\mu \\vec{H}\\]\nIf we have an oscillating \\(\\vec{H}\\) that will induce a circulating \\(\\vec{E}\\)\n\\[\\nabla \\times \\vec{H} =  - j \\omega \\epsilon \\vec{E}\\]\nIf we have an oscillating \\(\\vec{E}\\) that will induce a circulating \\(\\vec{H}\\)\nAn oscillating (for some reason) electric field, oscillating electric field will induce a circulating magnetic field.\n\n\n\nCurl Equations with Constitutive Relations plugged in\n\\[\n\\nabla \\times \\vec{E} = -j \\omega [\\mu] \\vec{H} \\tag{1}\n\\]\n\\[\n\\nabla \\times \\vec{H} = j \\omega [\\epsilon] \\vec{E} \\tag{2}\n\\]\nSolve (1) for \\(\\vec{H}\\)\n\\[\\frac{1}{j \\omega [\\mu]}  \\nabla \\times \\vec{E} = \\vec{H}\\tag{3}\\]\nSubstitute (3) into (2)\n\\[\n\\nabla \\times \\left( \\frac{1}{j \\omega [\\mu]}  \\nabla \\times \\vec{E} \\right) = -j \\omega [\\epsilon] \\vec{E}\n\\]\nThere you go!! That is the wave equation.\n\\[\n\\nabla \\times \\left( \\frac{1}{[\\mu]}  \\nabla \\times \\vec{E} \\right) = (j\\omega) (-j \\omega) [\\epsilon] \\vec{E}\n\\]\n\\[\n\\nabla \\times \\left( \\frac{1}{[\\mu]}  \\nabla \\times \\vec{E} \\right) = \\omega^2 [\\epsilon] \\vec{E}\n\\]\nHere we have anisotropic permeability and permitivity, it is usually used in computer simulations.\nWe want to bring permeability outside of that curl, so if permeability is inhomogeneous, it is a function of position so we cannot bring it outside.\nIf we assume linear, homogeneous, anisotropic materials,\n\\[\n\\nabla \\times \\left( \\frac{1}{[\\mu]}  \\nabla \\times \\vec{E} \\right) = \\omega^2 [\\epsilon] \\vec{E}\n\\]\n\\[\n\\nabla \\times \\left(  \\nabla \\times \\vec{E} \\right) = \\omega^2 \\mu \\epsilon \\vec{E}\n\\]\nVector Identity: \\(\\nabla \\times  \\nabla \\times \\vec{A} = \\nabla ( \\nabla \\cdot \\vec{A}) - \\nabla^2 \\vec{A}\\)\n\\[\n\\nabla ( \\nabla \\cdot \\vec{E}) = \\nabla^2 \\vec{E} + \\omega^2 \\mu \\epsilon \\vec{E} \\tag{4}\n\\]\nSince \\(\\nabla \\cdot \\vec{D} = 0\\),\n\\[\\nabla \\cdot \\vec{D} = 0 \\implies \\nabla \\cdot (\\epsilon \\vec{E}) = 0\\]\n\\[\\nabla \\cdot \\vec{E} = 0\\]\nSo the left-hand side of equation (4) becomes 0, we get\n\\[\\boxed{\\nabla^2 \\vec{E} + \\omega^2 \\mu \\epsilon \\vec{E} = 0} \\tag{5}\\]\nLet’s call \\(\\omega^2 \\mu \\epsilon = k^2\\), and \\(k\\) is called the wave number\n\\[k = \\omega \\sqrt{\\mu \\epsilon}\\]\nWe can also define \\(-\\omega^2 \\mu \\epsilon = \\gamma^2\\), \\(\\gamma\\) is called the complex propagation constant.\n\\[\\gamma^2 = -k^2\\]\nSo we can write frequency-domain wave equation as\n\\[\\boxed{\\nabla^2 \\vec{E} + k^2 \\vec{E} = 0}\\] \\[\\boxed{\\nabla^2 \\vec{E} - \\gamma^2 \\vec{E} = 0}\\]\n\n\n\nLHI stands for Linear, homogeneous, isotropic, \\[\\nabla^2 \\vec{E} + k^2 \\vec{E} = 0\\]\n\\[\\nabla^2 \\left( E_x \\hat{a}_x + E_y \\hat{a}_y + E_z \\hat{a}_z \\right) + k^2 \\left( E_x \\hat{a}_x + E_y \\hat{a}_y + E_z \\hat{a}_z \\right) = 0\\]\nDistribute\n\\[ \\nabla^2 E_x \\hat{a}_x + \\nabla^2 E_y \\hat{a}_y + \\nabla^2 E_z \\hat{a}_z +  k^2 E_x \\hat{a}_x + k^2 E_y \\hat{a}_y + k^2 E_z \\hat{a}_z = 0\\]\n\\[ \\left( \\nabla^2 E_x \\hat{a}_x  + k^2 E_x \\hat{a}_x \\right) + \\left( \\nabla^2 E_y \\hat{a}_y + k^2 E_y \\hat{a}_y \\right) + \\left( \\nabla^2 E_z \\hat{a}_z + k^2 E_z \\hat{a}_z \\right) = 0\\]\nSo each individual component has to equal to \\(0\\), so we can take our vector equation and turn it into three scalar equations\n\\[\\nabla^2 E_x \\hat{a}_x  + k^2 E_x \\hat{a}_x  = 0\\] \\[\\nabla^2 E_y \\hat{a}_y + k^2 E_y \\hat{a}_y  = 0\\] \\[ \\nabla^2 E_z \\hat{a}_z + k^2 E_z \\hat{a}_z = 0\\]\nThey have the same general solution… so we can just solve\n\\[\\nabla^2 E + k^2 E = 0\\]\nand reuse the solution to all three scalar equations.\nmathematical solution\n\\[\\nabla^2 E + k^2 E = 0\\]\n\\[\\implies E(\\vec{r}) =  E_{0}^{+} e^{-j \\vec{k} \\cdot \\vec{r}} + E_{0}^{-} e^{+j \\vec{k} \\cdot \\vec{r}}\\]\n\n\\(E_{0}^{+} e^{-j \\vec{k} \\cdot \\vec{r}}\\) is the forward wave\n\\(E_{0}^{-} e^{+j \\vec{k} \\cdot \\vec{r}}\\) is the backward wave\n\n\\[\\vec{E}(\\vec{r}) = E_x(\\vec{r}) \\hat{a}_x + E_y(\\vec{r}) \\hat{a}_y + E_z(\\vec{r}) \\hat{a}_z\\]\n\n\n\n\\[\\vec{E}(\\vec{r}) = \\vec{P} e^{-j \\vec{k} \\cdot \\vec{r}} \\tag{frequency-domain}\\] \\[\\vec{E}(\\vec{r}, t) =  \\vec{P} \\cos(\\omega t - \\vec{k} \\cdot \\vec{r}) \\tag{time-domain}\\]\n\n\\(\\vec{r} \\equiv x \\hat{a}_x + y \\hat{a}_y + z \\hat{a}_z\\)\n\\(\\vec{E} \\equiv \\text{total electric field intensity}\\)\n\\(\\vec{P} \\equiv \\text{polarization vector}\\)\n\\(\\vec{k} \\equiv \\text{wave vector}\\)\n\\(\\omega \\equiv 2 \\pi f \\equiv \\text{angular frequency}\\)s\n\\(t \\equiv \\text{time}\\)\n\nSo for the magnetic field, we can just use this result back into maxwell’s equations,\n\\[\\nabla \\times \\vec{E} = -j \\omega \\mu \\vec{H} \\tag{Faraday's Law}\\] \\[\\nabla \\times \\left(  \\vec{P} e^{-j \\vec{k} \\cdot \\vec{r}} \\right) = -j \\omega \\mu \\vec{H}\\]\n\\[\\boxed{\\frac{1}{\\omega \\mu} \\left(  \\vec{k} \\times \\vec{P} \\right) e^{-j \\vec{k} \\cdot \\vec{r}} = \\vec{H}}\\]\n\n\n\\[E(\\vec{r}) = E_{0}^{+} e^{-\\vec{\\gamma} \\cdot \\vec{r}} + E_{0}^{-} e^{+\\vec{\\gamma} \\cdot \\vec{r}}\\]\n\\[E(\\vec{r}) = \\vec{P} e^{-\\vec{\\gamma} \\cdot \\vec{r}} \\tag{frequency domain}\\]\n\\[\\vec{H} = \\frac{1}{j \\omega \\mu} ( \\vec{\\gamma} \\times \\vec{P}) e^{-\\vec{\\gamma} \\cdot \\vec{r}}\\]\nThe wave vector and propagation constant are related through: \\[\\vec{\\gamma} = j \\vec{k}\\]"
  },
  {
    "objectID": "work/courses/Applied_Electromagnetics.html#electromagnetic-waves",
    "href": "work/courses/Applied_Electromagnetics.html#electromagnetic-waves",
    "title": "Applied Electromagnetics",
    "section": "",
    "text": "Maxwell’s Equations predict waves\nDerivation and solution of the wave equation\n\nIn source-free media, \\(\\vec{J} = 0\\) and \\(\\rho_V = 0\\), maxwell’s equations in the frequency-domain become\nCurl Equations\n\\[\\nabla \\times \\vec{E} = -j\\omega \\vec{B}\\] \\[\\nabla \\times \\vec{H} = -j\\omega \\vec{D}\\]\nDivergence Equations\n\\[\\nabla \\cdot \\vec{D} = 0\\] \\[\\nabla \\cdot \\vec{B} = 0\\]\nConstitutive Relations\n\\[\\vec{D} = \\epsilon \\vec{E}\\] \\[\\vec{B} = \\epsilon \\vec{H}\\]\nSubstituting constitutive relations into the curl equations, we get:\n\\[\\nabla \\times \\vec{E} = -j \\omega \\mu \\vec{H}\\]\nIf we have an oscillating \\(\\vec{H}\\) that will induce a circulating \\(\\vec{E}\\)\n\\[\\nabla \\times \\vec{H} =  - j \\omega \\epsilon \\vec{E}\\]\nIf we have an oscillating \\(\\vec{E}\\) that will induce a circulating \\(\\vec{H}\\)\nAn oscillating (for some reason) electric field, oscillating electric field will induce a circulating magnetic field."
  },
  {
    "objectID": "work/courses/Applied_Electromagnetics.html#derive-wave-equation",
    "href": "work/courses/Applied_Electromagnetics.html#derive-wave-equation",
    "title": "Applied Electromagnetics",
    "section": "",
    "text": "Curl Equations with Constitutive Relations plugged in\n\\[\n\\nabla \\times \\vec{E} = -j \\omega [\\mu] \\vec{H} \\tag{1}\n\\]\n\\[\n\\nabla \\times \\vec{H} = j \\omega [\\epsilon] \\vec{E} \\tag{2}\n\\]\nSolve (1) for \\(\\vec{H}\\)\n\\[\\frac{1}{j \\omega [\\mu]}  \\nabla \\times \\vec{E} = \\vec{H}\\tag{3}\\]\nSubstitute (3) into (2)\n\\[\n\\nabla \\times \\left( \\frac{1}{j \\omega [\\mu]}  \\nabla \\times \\vec{E} \\right) = -j \\omega [\\epsilon] \\vec{E}\n\\]\nThere you go!! That is the wave equation.\n\\[\n\\nabla \\times \\left( \\frac{1}{[\\mu]}  \\nabla \\times \\vec{E} \\right) = (j\\omega) (-j \\omega) [\\epsilon] \\vec{E}\n\\]\n\\[\n\\nabla \\times \\left( \\frac{1}{[\\mu]}  \\nabla \\times \\vec{E} \\right) = \\omega^2 [\\epsilon] \\vec{E}\n\\]\nHere we have anisotropic permeability and permitivity, it is usually used in computer simulations.\nWe want to bring permeability outside of that curl, so if permeability is inhomogeneous, it is a function of position so we cannot bring it outside.\nIf we assume linear, homogeneous, anisotropic materials,\n\\[\n\\nabla \\times \\left( \\frac{1}{[\\mu]}  \\nabla \\times \\vec{E} \\right) = \\omega^2 [\\epsilon] \\vec{E}\n\\]\n\\[\n\\nabla \\times \\left(  \\nabla \\times \\vec{E} \\right) = \\omega^2 \\mu \\epsilon \\vec{E}\n\\]\nVector Identity: \\(\\nabla \\times  \\nabla \\times \\vec{A} = \\nabla ( \\nabla \\cdot \\vec{A}) - \\nabla^2 \\vec{A}\\)\n\\[\n\\nabla ( \\nabla \\cdot \\vec{E}) = \\nabla^2 \\vec{E} + \\omega^2 \\mu \\epsilon \\vec{E} \\tag{4}\n\\]\nSince \\(\\nabla \\cdot \\vec{D} = 0\\),\n\\[\\nabla \\cdot \\vec{D} = 0 \\implies \\nabla \\cdot (\\epsilon \\vec{E}) = 0\\]\n\\[\\nabla \\cdot \\vec{E} = 0\\]\nSo the left-hand side of equation (4) becomes 0, we get\n\\[\\boxed{\\nabla^2 \\vec{E} + \\omega^2 \\mu \\epsilon \\vec{E} = 0} \\tag{5}\\]\nLet’s call \\(\\omega^2 \\mu \\epsilon = k^2\\), and \\(k\\) is called the wave number\n\\[k = \\omega \\sqrt{\\mu \\epsilon}\\]\nWe can also define \\(-\\omega^2 \\mu \\epsilon = \\gamma^2\\), \\(\\gamma\\) is called the complex propagation constant.\n\\[\\gamma^2 = -k^2\\]\nSo we can write frequency-domain wave equation as\n\\[\\boxed{\\nabla^2 \\vec{E} + k^2 \\vec{E} = 0}\\] \\[\\boxed{\\nabla^2 \\vec{E} - \\gamma^2 \\vec{E} = 0}\\]"
  },
  {
    "objectID": "work/courses/Applied_Electromagnetics.html#components-decouple-in-lhi-media",
    "href": "work/courses/Applied_Electromagnetics.html#components-decouple-in-lhi-media",
    "title": "Applied Electromagnetics",
    "section": "",
    "text": "LHI stands for Linear, homogeneous, isotropic, \\[\\nabla^2 \\vec{E} + k^2 \\vec{E} = 0\\]\n\\[\\nabla^2 \\left( E_x \\hat{a}_x + E_y \\hat{a}_y + E_z \\hat{a}_z \\right) + k^2 \\left( E_x \\hat{a}_x + E_y \\hat{a}_y + E_z \\hat{a}_z \\right) = 0\\]\nDistribute\n\\[ \\nabla^2 E_x \\hat{a}_x + \\nabla^2 E_y \\hat{a}_y + \\nabla^2 E_z \\hat{a}_z +  k^2 E_x \\hat{a}_x + k^2 E_y \\hat{a}_y + k^2 E_z \\hat{a}_z = 0\\]\n\\[ \\left( \\nabla^2 E_x \\hat{a}_x  + k^2 E_x \\hat{a}_x \\right) + \\left( \\nabla^2 E_y \\hat{a}_y + k^2 E_y \\hat{a}_y \\right) + \\left( \\nabla^2 E_z \\hat{a}_z + k^2 E_z \\hat{a}_z \\right) = 0\\]\nSo each individual component has to equal to \\(0\\), so we can take our vector equation and turn it into three scalar equations\n\\[\\nabla^2 E_x \\hat{a}_x  + k^2 E_x \\hat{a}_x  = 0\\] \\[\\nabla^2 E_y \\hat{a}_y + k^2 E_y \\hat{a}_y  = 0\\] \\[ \\nabla^2 E_z \\hat{a}_z + k^2 E_z \\hat{a}_z = 0\\]\nThey have the same general solution… so we can just solve\n\\[\\nabla^2 E + k^2 E = 0\\]\nand reuse the solution to all three scalar equations.\nmathematical solution\n\\[\\nabla^2 E + k^2 E = 0\\]\n\\[\\implies E(\\vec{r}) =  E_{0}^{+} e^{-j \\vec{k} \\cdot \\vec{r}} + E_{0}^{-} e^{+j \\vec{k} \\cdot \\vec{r}}\\]\n\n\\(E_{0}^{+} e^{-j \\vec{k} \\cdot \\vec{r}}\\) is the forward wave\n\\(E_{0}^{-} e^{+j \\vec{k} \\cdot \\vec{r}}\\) is the backward wave\n\n\\[\\vec{E}(\\vec{r}) = E_x(\\vec{r}) \\hat{a}_x + E_y(\\vec{r}) \\hat{a}_y + E_z(\\vec{r}) \\hat{a}_z\\]"
  },
  {
    "objectID": "work/courses/Applied_Electromagnetics.html#general-expression-for-a-plane-wave",
    "href": "work/courses/Applied_Electromagnetics.html#general-expression-for-a-plane-wave",
    "title": "Applied Electromagnetics",
    "section": "",
    "text": "\\[\\vec{E}(\\vec{r}) = \\vec{P} e^{-j \\vec{k} \\cdot \\vec{r}} \\tag{frequency-domain}\\] \\[\\vec{E}(\\vec{r}, t) =  \\vec{P} \\cos(\\omega t - \\vec{k} \\cdot \\vec{r}) \\tag{time-domain}\\]\n\n\\(\\vec{r} \\equiv x \\hat{a}_x + y \\hat{a}_y + z \\hat{a}_z\\)\n\\(\\vec{E} \\equiv \\text{total electric field intensity}\\)\n\\(\\vec{P} \\equiv \\text{polarization vector}\\)\n\\(\\vec{k} \\equiv \\text{wave vector}\\)\n\\(\\omega \\equiv 2 \\pi f \\equiv \\text{angular frequency}\\)s\n\\(t \\equiv \\text{time}\\)\n\nSo for the magnetic field, we can just use this result back into maxwell’s equations,\n\\[\\nabla \\times \\vec{E} = -j \\omega \\mu \\vec{H} \\tag{Faraday's Law}\\] \\[\\nabla \\times \\left(  \\vec{P} e^{-j \\vec{k} \\cdot \\vec{r}} \\right) = -j \\omega \\mu \\vec{H}\\]\n\\[\\boxed{\\frac{1}{\\omega \\mu} \\left(  \\vec{k} \\times \\vec{P} \\right) e^{-j \\vec{k} \\cdot \\vec{r}} = \\vec{H}}\\]\n\n\n\\[E(\\vec{r}) = E_{0}^{+} e^{-\\vec{\\gamma} \\cdot \\vec{r}} + E_{0}^{-} e^{+\\vec{\\gamma} \\cdot \\vec{r}}\\]\n\\[E(\\vec{r}) = \\vec{P} e^{-\\vec{\\gamma} \\cdot \\vec{r}} \\tag{frequency domain}\\]\n\\[\\vec{H} = \\frac{1}{j \\omega \\mu} ( \\vec{\\gamma} \\times \\vec{P}) e^{-\\vec{\\gamma} \\cdot \\vec{r}}\\]\nThe wave vector and propagation constant are related through: \\[\\vec{\\gamma} = j \\vec{k}\\]"
  },
  {
    "objectID": "work/courses/pytorch.html",
    "href": "work/courses/pytorch.html",
    "title": "Deep Learning with PyTorch",
    "section": "",
    "text": "Instructor: Daniel Bourke\nYoutube\nPyTorch Docs\nWikipedia: Deep Learning\nHere we master the basics of Deep Learning through the PyTorch Workflow:\n\n\n\nAI includes machine learning, which includes deep learning. All three aim to approximate the rules of a system from examples.\nBefore using machine learning, ask: Can you write down all the rules to solve this problem? If yes, use a rule-based system—it’s simpler, faster, and more interpretable.\nBut when rules are too complex or unclear, machine learning or deep learning helps.\nDeep Learning is good for:\n\nProblems with long lists of rules\nContinually changing environments\nDiscovering insights within large collections of data\n\nDeep Learning is not good for:\n\nWhen you need explainability\nWhen the traditional approach is a better option\nWhen errors are unacceptable\n\nMachine Learning is better than Deep Learning at structured Data, neural networks typically work best with unstructured data.\n\n\n\n\n\n\n\nflowchart LR\n  A[Unstructured Data / Inputs] --&gt;B[Numbers]\n  B --&gt; C(Neural Network)\n  C --&gt; D[Weight Matrix]\n  D --&gt; E[Outputs]\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    A(Input Layer) --&gt; B[Hidden Layers]\n    B --&gt; C(Output Layers)\n\n\n\n\n\n\nEach layer is a combination of functions, linear or non-linear.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervised\nUnsupervised & Self-supervised\nTransfer\nReinforcement\n\n\n\n\nLot of Data that are labeled\nJust Data\nBuilding on top of already learned model\nAction and Reward\n\n\n\n\n\nIf you can encode something into numbers, you can build a deep learning model to find pattern in those numbers.\nComputer Vision, NLP, Recommendation, and literally anything complex."
  },
  {
    "objectID": "work/courses/pytorch.html#introduction",
    "href": "work/courses/pytorch.html#introduction",
    "title": "Deep Learning with PyTorch",
    "section": "",
    "text": "AI includes machine learning, which includes deep learning. All three aim to approximate the rules of a system from examples.\nBefore using machine learning, ask: Can you write down all the rules to solve this problem? If yes, use a rule-based system—it’s simpler, faster, and more interpretable.\nBut when rules are too complex or unclear, machine learning or deep learning helps.\nDeep Learning is good for:\n\nProblems with long lists of rules\nContinually changing environments\nDiscovering insights within large collections of data\n\nDeep Learning is not good for:\n\nWhen you need explainability\nWhen the traditional approach is a better option\nWhen errors are unacceptable\n\nMachine Learning is better than Deep Learning at structured Data, neural networks typically work best with unstructured data.\n\n\n\n\n\n\n\nflowchart LR\n  A[Unstructured Data / Inputs] --&gt;B[Numbers]\n  B --&gt; C(Neural Network)\n  C --&gt; D[Weight Matrix]\n  D --&gt; E[Outputs]\n\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    A(Input Layer) --&gt; B[Hidden Layers]\n    B --&gt; C(Output Layers)\n\n\n\n\n\n\nEach layer is a combination of functions, linear or non-linear.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervised\nUnsupervised & Self-supervised\nTransfer\nReinforcement\n\n\n\n\nLot of Data that are labeled\nJust Data\nBuilding on top of already learned model\nAction and Reward\n\n\n\n\n\nIf you can encode something into numbers, you can build a deep learning model to find pattern in those numbers.\nComputer Vision, NLP, Recommendation, and literally anything complex."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alex Meng",
    "section": "",
    "text": "I am an incoming PhD student in the Department of Electrical and Computer Engineering at Duke University, fortunate to be advised by Prof. Natalia M. Litchinitser. Previously, I was an undergrad at Duke University Double majoring in Electrical and Computer Engineering and Computer Science."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Alex Meng",
    "section": "",
    "text": "I am an incoming PhD student in the Department of Electrical and Computer Engineering at Duke University, fortunate to be advised by Prof. Natalia M. Litchinitser. Previously, I was an undergrad at Duke University Double majoring in Electrical and Computer Engineering and Computer Science."
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Alex Meng",
    "section": "Research Interests",
    "text": "Research Interests\n\nQuantum + Photonic Computing: Nanophotonics, AI/ML for designing optical metasurfaces, Optical Neural Networks, Photonic Integrated Circuits, silicon photonics"
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Alex Meng",
    "section": "News",
    "text": "News\n[May 2025] Graduated from Duke Undergraduate, excited to be going into my PhD!"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "AM",
    "section": "",
    "text": "Why Robots Need Brains Made of Light\n\n\n\nAI\n\nPhotonics\n\n\n\n\n\n\n\n\n\nMay 22, 2025\n\n\nAlex Meng\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/about.html",
    "href": "blog/about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog/posts/post-with-code/index.html",
    "href": "blog/posts/post-with-code/index.html",
    "title": "Why Robots Need Brains Made of Light",
    "section": "",
    "text": "Imagine you’re standing in your kitchen with a helper robot. You want to teach it how to pick up a weirdly shaped mug. You don’t want to plug it into a supercomputer, wait for hours, or send its data to the cloud. You want it to learn right there, on the spot—fast, efficient, and offline.\nThat’s the dream. But with today’s AI infrastructure, it’s still far from reality."
  },
  {
    "objectID": "blog/posts/post-with-code/index.html#the-problem-with-modern-ai-training",
    "href": "blog/posts/post-with-code/index.html#the-problem-with-modern-ai-training",
    "title": "Why Robots Need Brains Made of Light",
    "section": "The Problem with Modern AI Training",
    "text": "The Problem with Modern AI Training\nMost AI today is trained on massive data centers using powerful GPUs. This works great for large-scale models—but it completely breaks down for embodied intelligence, like robots.\nWhy?\n\nHigh energy consumption: A single GPU can consume 300W+. That’s more power than your fridge.\nSlow learning loops: Training even a small model can take hours or days.\nDependency on the cloud: Real-time response is impossible when your robot needs to “phone home” to think.\nBig form factors: Heavy compute modules don’t fit into lightweight, mobile robots.\n\nIf we want robots to truly live and learn in the real world, they need a new kind of brain."
  },
  {
    "objectID": "blog/posts/post-with-code/index.html#optical-analog-neural-networks",
    "href": "blog/posts/post-with-code/index.html#optical-analog-neural-networks",
    "title": "Why Robots Need Brains Made of Light",
    "section": "Optical Analog Neural Networks",
    "text": "Optical Analog Neural Networks\nOptical analog neural networks are a radical shift in how we compute. Instead of using electricity and digital logic, they use light to do inference—and potentially even learning.\nHere’s how they work:\n\nLight as data: Inputs are encoded as light waves.\nOptics as weights: Layers of lenses or diffractive structures bend light to perform matrix multiplications.\nComputation is free: Inference happens as light passes through. No clock cycles. No energy cost beyond the laser."
  },
  {
    "objectID": "blog/posts/post-with-code/index.html#why-this-matters-for-robots",
    "href": "blog/posts/post-with-code/index.html#why-this-matters-for-robots",
    "title": "Why Robots Need Brains Made of Light",
    "section": "Why This Matters for Robots",
    "text": "Why This Matters for Robots\nWith optical neural networks, we could give robots something revolutionary:\n\nLearn on the Spot Training and inference could happen in-situ, without ever leaving the robot. If you show it a new tool or task, it could adapt in real time.\nTiny and Lightweight Optical layers can be embedded directly into sensors—no bulky GPUs needed.\nUltra-Low Power Since light travels through passive structures, inference consumes almost zero energy.\nNo Cloud Dependency On-device learning means no latency, no data privacy risks, and no need for connectivity."
  },
  {
    "objectID": "blog/posts/post-with-code/index.html#the-future-robots-with-brains-made-of-light",
    "href": "blog/posts/post-with-code/index.html#the-future-robots-with-brains-made-of-light",
    "title": "Why Robots Need Brains Made of Light",
    "section": "The Future: Robots with Brains Made of Light",
    "text": "The Future: Robots with Brains Made of Light\nThis isn’t science fiction. We’re already seeing early versions of:\n\nProgrammable metasurfaces that adaptively modify light paths\nDiffractive optical neural networks that do real-time classification\nIntegrated photonic chips that route and compute with light on a chip\n\nCombine that with reinforcement learning and world models, and you get a robot that can see, think, and learn physically, just like humans do."
  },
  {
    "objectID": "blog/posts/post-with-code/index.html#toward-truly-embodied-intelligence",
    "href": "blog/posts/post-with-code/index.html#toward-truly-embodied-intelligence",
    "title": "Why Robots Need Brains Made of Light",
    "section": "Toward Truly Embodied Intelligence",
    "text": "Toward Truly Embodied Intelligence\nTo build robots that operate in the messiness of the real world—not just on factory floors—we need:\n\nSmarter sensors (light field, polarization, event-based)\nFaster, lower-power compute (optics over electronics)\nIn-situ learning via analog computation\n\n\nIf we want robots to think and learn like humans,\nthey need brains made of light.\n\nThis is where AI meets physics. And it’s how we take the leap from simulated intelligence to real-world, embodied intelligence.\n\nWritten by someone who believes the future of AI isn’t just faster—it’s optical."
  },
  {
    "objectID": "work/papers/photonics.html",
    "href": "work/papers/photonics.html",
    "title": "Optical Computing",
    "section": "",
    "text": "Optical Computing\nWetzstein, G., Ozcan, A., Gigan, S. et al. Inference in artificial intelligence with deep optics and photonics. Nature 588, 39–47 (2020). https://doi.org/10.1038/s41586-020-2973-6\nGeneral Optical computing is not practical yet, but using optics for inference for visual computing applications is practical. This paper is a review on recent work on optical computing for AI.\nMotivation 1: Edge devices (cameras, cars, robots, headsets, IoT) need leaner (low latency, light, small, low power) computational imaging systems.\nOptical computing systems promise small form factor, massive parallelism, little to no power consumption. Optical interconnects are already widely used in data centers today.\nLinear optical elements can calculate convolution, fourier transforms, random projections, as a byproduct of light-matter interaction. These operations are what’s needed for DNNs.\n“Incorporating all-optical nonlinearities into photonic circuits is one of the key requirements for truly deep photonic networks. Yet, the challenge of efficiently implementing photonic nonlinear activation functions at low optical signal intensities was one of the primary reasons that interest in ONNs waned in the 1990s. Creative approaches from the last decade, such as nonlinear thresholders based on all-optical micro-ring resonators35, saturable absorbers29,36, electro-absorption modulators37, or hybrid electro-optical approaches38, represent possible solutions for overcoming this challenge in the near future.”\nAlthough programmability has traditionally been more difficult with photonic systems, first steps towards simplifying the process have recently been demonstrated\n“One direction that seems particularly well suited for optical and photonic processing is optical inference with incoherent light to rapidly process scene information under ambient lighting conditions. Such an approach presents many exciting opportunities for autonomous vehicles, robotics and computer vision, which we discuss next.”"
  },
  {
    "objectID": "work/courses/quant.html",
    "href": "work/courses/quant.html",
    "title": "Problem Solving",
    "section": "",
    "text": "Being a quant is knowing how to solve problems with logic, math, and intuition. These Problems come from A practical guide to Quantitative Finance Interviews by Xinfeng Zhou.\n\n\n\n\nFive pirates looted a chest full of 100 gold coins. Being a bunch of democratic pirates, they agree on the following method to divide the loot:\nThe most senior pirate will propose a distribution of the coins. All pirates, including the most senior pirate, will then vote. If at least \\(50\\%\\) of the pirates (\\(3\\) pirates in this case) accept the proposal, the gold is divided as proposed. If not, the most senior pirate will be fed to shark and the process starts over with the next most senior pirate… The process is repeated until a plan is approved. You can assume that all pirates are perfectly rational: they want to stay alive first and to get as much gold as possible second. Finally, being blood-thirsty pirates, they want to have fewer pirates on the boat if given a choice between otherwise equal outcomes.\nHow will the gold coins be divided in the end?\n\n\nAnswer\n\nI have no idea what the five pirates will do, lemme consider a simpler case, 1 pirate.\n1 pirate. Pirate 1 propose to distribute all 100 gold coins to himself, and accept the proposal.\n\\[100 \\text{ coins to pirate 1}\\]\n2 pirates. Pirate 2 proposes to get all the gold, 50% good, gets all the gold.\n\\[100 \\text{ coins to pirate 2}\\]\n3 pirates. From the perspective of pirate 1, pirate 1 gets nothing if pirate 3 pirate 3 gets voted out (back to case 2), so pirate 1 will try to make pirate 3 win, iff pirate 1 gets at least some benefits. Pirate 3 knows that, so pirate 3 will give 1 coin to pirate 1 and 99 coins to pirate 3, since pirate 1 will think anything is better than nothing.\n\\[1 \\text{ coin to pirate 1}, 99 \\text{ coins to pirate 3}\\]\n4 pirates. If pirate 4 gives to pirate 2, pirate 2 will vote for pirate 4 because if he doesn’t, it will be back to 3 pirates case where he doesn’t get anything…So\n\\[1 \\text{ coin pirate 2}, 99 \\text{ coins pirate 4}\\]\n5 pirates. Pirate 5 will give coinds to pirate 1 and pirate 3, because doing that will allow them to get some coins, where if he gets voted out, in 4 pirates case they don’t get anything…So\n\\[\\boxed{1 \\text{ coin for pirate 1}, 1 \\text{ coin for pirate 3}, 98 \\text{ coins for pirate 5}}\\]\nWe can actually formualte a generalizable law from this using mathematics."
  },
  {
    "objectID": "work/courses/quant.html#problem-simplification",
    "href": "work/courses/quant.html#problem-simplification",
    "title": "Problem Solving",
    "section": "",
    "text": "Five pirates looted a chest full of 100 gold coins. Being a bunch of democratic pirates, they agree on the following method to divide the loot:\nThe most senior pirate will propose a distribution of the coins. All pirates, including the most senior pirate, will then vote. If at least \\(50\\%\\) of the pirates (\\(3\\) pirates in this case) accept the proposal, the gold is divided as proposed. If not, the most senior pirate will be fed to shark and the process starts over with the next most senior pirate… The process is repeated until a plan is approved. You can assume that all pirates are perfectly rational: they want to stay alive first and to get as much gold as possible second. Finally, being blood-thirsty pirates, they want to have fewer pirates on the boat if given a choice between otherwise equal outcomes.\nHow will the gold coins be divided in the end?\n\n\nAnswer\n\nI have no idea what the five pirates will do, lemme consider a simpler case, 1 pirate.\n1 pirate. Pirate 1 propose to distribute all 100 gold coins to himself, and accept the proposal.\n\\[100 \\text{ coins to pirate 1}\\]\n2 pirates. Pirate 2 proposes to get all the gold, 50% good, gets all the gold.\n\\[100 \\text{ coins to pirate 2}\\]\n3 pirates. From the perspective of pirate 1, pirate 1 gets nothing if pirate 3 pirate 3 gets voted out (back to case 2), so pirate 1 will try to make pirate 3 win, iff pirate 1 gets at least some benefits. Pirate 3 knows that, so pirate 3 will give 1 coin to pirate 1 and 99 coins to pirate 3, since pirate 1 will think anything is better than nothing.\n\\[1 \\text{ coin to pirate 1}, 99 \\text{ coins to pirate 3}\\]\n4 pirates. If pirate 4 gives to pirate 2, pirate 2 will vote for pirate 4 because if he doesn’t, it will be back to 3 pirates case where he doesn’t get anything…So\n\\[1 \\text{ coin pirate 2}, 99 \\text{ coins pirate 4}\\]\n5 pirates. Pirate 5 will give coinds to pirate 1 and pirate 3, because doing that will allow them to get some coins, where if he gets voted out, in 4 pirates case they don’t get anything…So\n\\[\\boxed{1 \\text{ coin for pirate 1}, 1 \\text{ coin for pirate 3}, 98 \\text{ coins for pirate 5}}\\]\nWe can actually formualte a generalizable law from this using mathematics."
  },
  {
    "objectID": "work/courses/ee647nanophotonics.html",
    "href": "work/courses/ee647nanophotonics.html",
    "title": "EE647 Nanophotonics (KAIST)",
    "section": "",
    "text": "EE647 Nanophotonics (KAIST)\nYoutube Playlist Self-Study: link\nInstructor: Min Seok Jang\nBegin Date: 6/6/2025\nExpected End Date: 8/1/2025"
  },
  {
    "objectID": "work/courses/dsa.html",
    "href": "work/courses/dsa.html",
    "title": "Data Structures and Algorithms",
    "section": "",
    "text": "Data Structures and Algorithms"
  },
  {
    "objectID": "work/courses/nanophotonics.html",
    "href": "work/courses/nanophotonics.html",
    "title": "Nanophotonics",
    "section": "",
    "text": "Is it possible to design artificial materials that have electromagnetic roperties not found in nature?\nYes. There are in general two types:\n\nNegative Index: \\(\\epsilon &lt; 0, \\mu &lt; 0\\)\nHyperbolic: \\(\\epsilon_{||} \\epsilon_{\\perp} &lt; 0\\)\n\n\n\nMetamaterials are composed of carefully engineered subwavelength structures (meta-atoms)\n\\[\\text{Actual Atom } \\lambda \\approx 1 \\times 10^{-4} \\mu m \\] \\[\\text{EM wave of interest } \\lambda \\approx 1  \\mu m \\]\n\\[\\implies \\text{Room for engineering } \\lambda \\approx [0.01, 0.1] \\mu m \\]\n\n\n\nWhen we have composite media, it is not merely a sum of permittivity. The effective dielectric constant of the mixture \\(\\epsilon_{eff}\\) depends on not only the volume fill fraction but also the detailed geometric structure of the materials. Here’s more details on how to calculate effective permitivity of composite media.\nWhen we have a layered structure, the \\(\\vec{E}_{||}\\) sees a “series capacitor” connection. If we have layered structure of two materials with length \\(d_a\\) and \\(d_b\\),\n\\[\\frac{1}{\\epsilon_{||}} = \\frac{1}{d_a + d_b} \\left( \\frac{d_a}{\\epsilon_a} + \\frac{d_b}{\\epsilon_b} \\right)\\]\n\n\n\n\nFirst metamaterial got suggested, but since it must be 3D, it is very difficult to fabricate. In order to use a metamaterial, since they are made of metal, highly absorbing, light cannot penetrate through metamaterials.\nBulk metamaterials is difficult, so why not just do a surface? so this is how metasurfaces came about.\n\n\nIf a lifeguard want to rescue a drowning man, the lifeguard needs to find out the optimal route. Since swimming speed is much slower than the speed at which he cna run, he must optimize the path based on his speed. This leads to Snell’s Law: Light chooses the path that has minimal action.\nThis is what happens in typical situation. Metasurface acts like a wall, very thin.\nBefore:\n\\[n_t \\sin \\theta_t - n_i sin \\theta_i = 0\\]\nNow:\nAccounting for the time the lifeguard moves through the wall\n\\[n_t \\sin \\theta_t - n_i sin \\theta_i = \\frac{1}{k_0} \\frac{d \\Phi}{dx}\\]\nThe lifeguard wants to minimize the time to go through the wall. Making metasurface is designing the wall shape so we can control the propagation of light.\n\n\n\nHuygen’s principle states that in order to describe the propagation of wave and each point of wavefront, you can imagine that each point of wavefront acts as the surce of wave, so you can have a diverging.\nMetaatoms have different response to the incident light, so some metaatoms crates the wavefront with a relatively smaller phase shift, and some create larger phase shift. Even though it’s thin and flat, you can deflect electromagnetic wave."
  },
  {
    "objectID": "work/courses/nanophotonics.html#metamaterials",
    "href": "work/courses/nanophotonics.html#metamaterials",
    "title": "Nanophotonics",
    "section": "",
    "text": "Is it possible to design artificial materials that have electromagnetic roperties not found in nature?\nYes. There are in general two types:\n\nNegative Index: \\(\\epsilon &lt; 0, \\mu &lt; 0\\)\nHyperbolic: \\(\\epsilon_{||} \\epsilon_{\\perp} &lt; 0\\)\n\n\n\nMetamaterials are composed of carefully engineered subwavelength structures (meta-atoms)\n\\[\\text{Actual Atom } \\lambda \\approx 1 \\times 10^{-4} \\mu m \\] \\[\\text{EM wave of interest } \\lambda \\approx 1  \\mu m \\]\n\\[\\implies \\text{Room for engineering } \\lambda \\approx [0.01, 0.1] \\mu m \\]\n\n\n\nWhen we have composite media, it is not merely a sum of permittivity. The effective dielectric constant of the mixture \\(\\epsilon_{eff}\\) depends on not only the volume fill fraction but also the detailed geometric structure of the materials. Here’s more details on how to calculate effective permitivity of composite media.\nWhen we have a layered structure, the \\(\\vec{E}_{||}\\) sees a “series capacitor” connection. If we have layered structure of two materials with length \\(d_a\\) and \\(d_b\\),\n\\[\\frac{1}{\\epsilon_{||}} = \\frac{1}{d_a + d_b} \\left( \\frac{d_a}{\\epsilon_a} + \\frac{d_b}{\\epsilon_b} \\right)\\]"
  },
  {
    "objectID": "work/courses/nanophotonics.html#metasurfaces",
    "href": "work/courses/nanophotonics.html#metasurfaces",
    "title": "Nanophotonics",
    "section": "",
    "text": "First metamaterial got suggested, but since it must be 3D, it is very difficult to fabricate. In order to use a metamaterial, since they are made of metal, highly absorbing, light cannot penetrate through metamaterials.\nBulk metamaterials is difficult, so why not just do a surface? so this is how metasurfaces came about.\n\n\nIf a lifeguard want to rescue a drowning man, the lifeguard needs to find out the optimal route. Since swimming speed is much slower than the speed at which he cna run, he must optimize the path based on his speed. This leads to Snell’s Law: Light chooses the path that has minimal action.\nThis is what happens in typical situation. Metasurface acts like a wall, very thin.\nBefore:\n\\[n_t \\sin \\theta_t - n_i sin \\theta_i = 0\\]\nNow:\nAccounting for the time the lifeguard moves through the wall\n\\[n_t \\sin \\theta_t - n_i sin \\theta_i = \\frac{1}{k_0} \\frac{d \\Phi}{dx}\\]\nThe lifeguard wants to minimize the time to go through the wall. Making metasurface is designing the wall shape so we can control the propagation of light.\n\n\n\nHuygen’s principle states that in order to describe the propagation of wave and each point of wavefront, you can imagine that each point of wavefront acts as the surce of wave, so you can have a diverging.\nMetaatoms have different response to the incident light, so some metaatoms crates the wavefront with a relatively smaller phase shift, and some create larger phase shift. Even though it’s thin and flat, you can deflect electromagnetic wave."
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#paperspace-your-dl-workstation-in-cloud",
    "href": "work/courses/fastai_lesson3.html#paperspace-your-dl-workstation-in-cloud",
    "title": "Lesson 3",
    "section": "Paperspace: Your DL Workstation in Cloud!",
    "text": "Paperspace: Your DL Workstation in Cloud!\n\nDoes Jeremy speak highly of it? Why?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#jupyterlab-real-beginner-friendly",
    "href": "work/courses/fastai_lesson3.html#jupyterlab-real-beginner-friendly",
    "title": "Lesson 3",
    "section": "JupyterLab: Real Beginner Friendly",
    "text": "JupyterLab: Real Beginner Friendly\n\nWhy is JupyterLab good for beginners?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#make-a-better-pet-detector",
    "href": "work/courses/fastai_lesson3.html#make-a-better-pet-detector",
    "title": "Lesson 3",
    "section": "Make a Better Pet Detector",
    "text": "Make a Better Pet Detector\n\nAfter training, think about how to improve the model"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#comparison-of-all-image-models",
    "href": "work/courses/fastai_lesson3.html#comparison-of-all-image-models",
    "title": "Lesson 3",
    "section": "Comparison of All (Image) Models",
    "text": "Comparison of All (Image) Models\n\nDid anyone compare most image models and share the findings?\n\nWhere to find the notebook for comparison?\n\nWhich 3 criteria are used for comparison?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#try-out-new-models",
    "href": "work/courses/fastai_lesson3.html#try-out-new-models",
    "title": "Lesson 3",
    "section": "Try Out New Models",
    "text": "Try Out New Models\n\nHow to select and try out models with high scores\n\nWhere is the train.ipynb file?\n\nHow to try models on TIMM?\n\nHow to compare them by loss?\n\nWhy is this model impressive?\n\nWhat can the name of a model tell us?\n\nWhy does Jeremy only train for 3 epochs? (18:58)"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#get-the-categories-of-a-model",
    "href": "work/courses/fastai_lesson3.html#get-the-categories-of-a-model",
    "title": "Lesson 3",
    "section": "Get the Categories of a Model",
    "text": "Get the Categories of a Model\n\nHow to get label/category info from the model\n\nThe rest we learned from the last lecture"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#whats-in-the-model",
    "href": "work/courses/fastai_lesson3.html#whats-in-the-model",
    "title": "Lesson 3",
    "section": "What’s in the Model",
    "text": "What’s in the Model\n\nWhat two things are stored in the model?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#what-does-model-architecture-look-like",
    "href": "work/courses/fastai_lesson3.html#what-does-model-architecture-look-like",
    "title": "Lesson 3",
    "section": "What Does Model Architecture Look Like?",
    "text": "What Does Model Architecture Look Like?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#parameters-of-a-model",
    "href": "work/courses/fastai_lesson3.html#parameters-of-a-model",
    "title": "Lesson 3",
    "section": "Parameters of a Model",
    "text": "Parameters of a Model\n\nHow to zoom in on a model layer\n\nHow to check out a layer’s parameters\n\nWhat do a layer’s parameters look like?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#the-investigating-questions",
    "href": "work/courses/fastai_lesson3.html#the-investigating-questions",
    "title": "Lesson 3",
    "section": "The Investigating Questions",
    "text": "The Investigating Questions\n\nWhat are the weights/numbers?\n\nHow can they reveal something important?\n\nWhere is the notebook on how neural nets work?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#create-a-general-quadratic-function",
    "href": "work/courses/fastai_lesson3.html#create-a-general-quadratic-function",
    "title": "Lesson 3",
    "section": "Create a General Quadratic Function",
    "text": "Create a General Quadratic Function\n\nHow to create a function that can generate any quadratic by changing 3 parameters\n\nHow to generate output from a specific quadratic by changing 1 parameter\n\nWhy create a general function with multiple parameters instead of hard-coding coefficients?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#fit-a-function-by-hand-and-eye",
    "href": "work/courses/fastai_lesson3.html#fit-a-function-by-hand-and-eye",
    "title": "Lesson 3",
    "section": "Fit a Function by Hand and Eye",
    "text": "Fit a Function by Hand and Eye\n\nWhat does “fit a function” mean? (tune parameters based on data)\n\nHow to create a random dataset\n\nHow to fit the quadratic by hand using Jupyter widgets\n\nLimitations of the manual/visual approach\n\nWhere is this notebook?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#loss-fit-a-function-better-without-eyes",
    "href": "work/courses/fastai_lesson3.html#loss-fit-a-function-better-without-eyes",
    "title": "Lesson 3",
    "section": "Loss: Fit a Function Better Without Eyes",
    "text": "Loss: Fit a Function Better Without Eyes\n\nWhy we need a loss/loss function\n\nWhat is mean squared error?\n\nHow loss helps improve accuracy over manual fitting"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#automate-the-search-of-parameters",
    "href": "work/courses/fastai_lesson3.html#automate-the-search-of-parameters",
    "title": "Lesson 3",
    "section": "Automate the Search of Parameters",
    "text": "Automate the Search of Parameters\n\nHow to update parameters to reduce loss\n\nDerivative material on Khan Academy?\n\nWhat do you need to know about derivatives now? (34:26)\n\nWhat is the slope/gradient?\n\nCan PyTorch compute gradients for us?\n\nHow to define a loss function on the quadratic (35:02)\n\nWhat to know about tensors and derivatives (36:02)\n\nHow to create a rank-1 tensor for storing parameters (36:49)\n\nHow to enable PyTorch gradient tracking (37:10)\n\nHow to calculate gradients from loss (37:38)\n\nWhat do the gradients mean? (38:34)\n\nHow to update parameters using gradients (39:18)\n\nHow to automate the full gradient descent process (41:05)\n\nWhy this process is called gradient descent\n\nRelated notebook"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#the-mathematical-functions",
    "href": "work/courses/fastai_lesson3.html#the-mathematical-functions",
    "title": "Lesson 3",
    "section": "The Mathematical Functions",
    "text": "The Mathematical Functions\n\nBeyond data/loss/derivative, what else is essential for learning parameters?\n\nWhy not use just quadratic functions?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#relu-rectified-linear-function",
    "href": "work/courses/fastai_lesson3.html#relu-rectified-linear-function",
    "title": "Lesson 3",
    "section": "ReLU: Rectified Linear Function",
    "text": "ReLU: Rectified Linear Function\n\nReal-world models need complex functions – how complex?\n\nCan we build infinite complexity using simple additions?\n\nWhat is a rectified linear function?\n\nWhat does a ReLU plot look like?\n\nAdjusting the 2 parameters with widgets\n\nHow the function varies under different parameters (44:46)"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#infinitely-complex-function",
    "href": "work/courses/fastai_lesson3.html#infinitely-complex-function",
    "title": "Lesson 3",
    "section": "Infinitely Complex Function",
    "text": "Infinitely Complex Function\n\nHow powerful are combinations of simple functions?\n\nCreate a double ReLU function and adjust 4 parameters\n\nComparison between double and single ReLU\n\nHow complex can it get with millions of ReLUs?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#circles-to-an-owl",
    "href": "work/courses/fastai_lesson3.html#circles-to-an-owl",
    "title": "Lesson 3",
    "section": "2 Circles to an Owl",
    "text": "2 Circles to an Owl\n\nConcise summary of core deep learning concepts"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#a-chart-of-all-image-models-compared",
    "href": "work/courses/fastai_lesson3.html#a-chart-of-all-image-models-compared",
    "title": "Lesson 3",
    "section": "A Chart of All Image Models Compared",
    "text": "A Chart of All Image Models Compared\n\nCan it be done with brute-force code?\n\nDid Jeremy look for this comparison?\n\nWhat is the wrong way students use the chart? (50:45)\n\nHow Jeremy uses the chart\n\nHow he selects which models to try step-by-step"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#do-i-have-enough-data",
    "href": "work/courses/fastai_lesson3.html#do-i-have-enough-data",
    "title": "Lesson 3",
    "section": "Do I Have Enough Data?",
    "text": "Do I Have Enough Data?\n\nDid you train a model on your dataset?\n\nIs the result satisfying?\n\nMistake often made in DL industry (52:55)\n\nJeremy’s suggestions\n\nRole of semi-supervised learning and augmentation\n\nHow labeled and unlabeled data can help"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#interpret-gradients-in-unit",
    "href": "work/courses/fastai_lesson3.html#interpret-gradients-in-unit",
    "title": "Lesson 3",
    "section": "Interpret Gradients in Unit",
    "text": "Interpret Gradients in Unit\n\nHow much loss decreases when a parameter increases by 1 unit? (55:24)"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#learning-rate",
    "href": "work/courses/fastai_lesson3.html#learning-rate",
    "title": "Lesson 3",
    "section": "Learning Rate",
    "text": "Learning Rate\n\nWhy avoid large step updates?\n\nJeremy uses quadratic zoom analogy – why?\n\nWhat happens with large step updates? (57:19)\n\nIs large loss drop always due to large parameter increase?\n\nWhat is the learning rate? Why small? How to choose it? (58:07)\n\nToo large? Too small? Consequences"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#break",
    "href": "work/courses/fastai_lesson3.html#break",
    "title": "Lesson 3",
    "section": "Break",
    "text": "Break"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#matrix-multiplication",
    "href": "work/courses/fastai_lesson3.html#matrix-multiplication",
    "title": "Lesson 3",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nHow to compute millions of ReLUs efficiently\n\nWhat linear algebra you need (1:01:33)\n\nHow easy is matrix multiplication? (1:01:51)\n\nDataset and parameters in matrix multiplication\n\nDoes matrix multiplication do the rectifying?\n\nWhat are GPUs good at? (1:03:49)"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#build-a-regression-model-in-spreadsheet",
    "href": "work/courses/fastai_lesson3.html#build-a-regression-model-in-spreadsheet",
    "title": "Lesson 3",
    "section": "Build a Regression Model in Spreadsheet",
    "text": "Build a Regression Model in Spreadsheet\n\nTitanic competition on Kaggle intro (1:05:01)\n\nWhat is the dataset? (1:05:18)\n\nWhat to do with train.csv\n\nClean and transform dataset (1:07:17)\n\nPrepare parameters for multiplication (1:08:50)\n\nProblem with ‘Fare’ column scale (1:09:35)\n\nNormalize ‘Fare’, ‘Age’\n\nWhat is data normalization?\n\nDoes fastai do this? Will we learn how?\n\nWhy log-transform ‘Fare’? (1:10:59)\n\nWhy even distribution matters\n\nHow to use MMULT in spreadsheet (1:11:56)\n\nUse MMULT to add constant\n\nModel result (1:13:41)\n\nLinear regression only? No ReLU?\n\nCan gradient descent solve regression? How?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#build-a-neural-net-by-adding-two-regression-models",
    "href": "work/courses/fastai_lesson3.html#build-a-neural-net-by-adding-two-regression-models",
    "title": "Lesson 3",
    "section": "Build a Neural Net by Adding Two Regression Models",
    "text": "Build a Neural Net by Adding Two Regression Models\n\nWhat it takes to build a neural net\n\nWhy not add results before ReLU?\n\nWhy add after ReLU?\n\nWhat the prediction looks like\n\nNow update 2 sets of parameters"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#matrix-multiplication-makes-training-faster",
    "href": "work/courses/fastai_lesson3.html#matrix-multiplication-makes-training-faster",
    "title": "Lesson 3",
    "section": "Matrix Multiplication Makes Training Faster",
    "text": "Matrix Multiplication Makes Training Faster\n\nHow to use MMULT instead of individual additions"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#watch-out-its-chapter-4",
    "href": "work/courses/fastai_lesson3.html#watch-out-its-chapter-4",
    "title": "Lesson 3",
    "section": "Watch Out! It’s Chapter 4",
    "text": "Watch Out! It’s Chapter 4\n\nTry the Titanic competition\n\nWhy Chapter 4 is tough for many\n\nHow to work through spreadsheet examples"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#create-dummy-variables-of-3-classes",
    "href": "work/courses/fastai_lesson3.html#create-dummy-variables-of-3-classes",
    "title": "Lesson 3",
    "section": "Create Dummy Variables of 3 Classes",
    "text": "Create Dummy Variables of 3 Classes\n\nDo we need only 2 columns for 3-class dummy variable?"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#taste-nlp",
    "href": "work/courses/fastai_lesson3.html#taste-nlp",
    "title": "Lesson 3",
    "section": "Taste NLP",
    "text": "Taste NLP\n\nWhat NLP models do\n\nOpportunities for non-English speaker students\n\nWhat tasks NLP can do (1:25:57)"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#fastai-nlp-library-vs-hugging-face",
    "href": "work/courses/fastai_lesson3.html#fastai-nlp-library-vs-hugging-face",
    "title": "Lesson 3",
    "section": "fastai NLP Library vs Hugging Face",
    "text": "fastai NLP Library vs Hugging Face\n\nHow these libraries differ\n\nWhy we use transformers in this lecture"
  },
  {
    "objectID": "work/courses/fastai_lesson3.html#homework",
    "href": "work/courses/fastai_lesson3.html#homework",
    "title": "Lesson 3",
    "section": "Homework",
    "text": "Homework\n\nHomework to prepare for the next lesson"
  },
  {
    "objectID": "work/summary.html",
    "href": "work/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever."
  },
  {
    "objectID": "work/references.html",
    "href": "work/references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "work/textbooks/balanis.html",
    "href": "work/textbooks/balanis.html",
    "title": "Advanced Engineering Electromagnetics - C. Balanis",
    "section": "",
    "text": "Link: Internet Archive\n\n\n\n\n\n\nExpand\n\n\nWho is James Clerk Maxwell?\n\n\n\nAnswer\n\n\n\n\nJames Clerk Maxwell\n\n\nA Scottish physicist and mathematician that lived from 1831 to 1879.\nThe Father of Modern Physics\n\nSee my notes on Dan Fleisch’s A student’s guide to Maxwell’s Equations for detailed explanation of the differential and integral forms of the four maxwell’s equations.\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\n\n\nExpand\n\n\n\nWhat is Circuit Theory?\n\n\n\nAnswer\n\nA special case of electromagnetic theory, when the physical dimensions of the circuit are small compared to the wavelength.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpand"
  },
  {
    "objectID": "work/textbooks/balanis.html#time-varying-and-time-harmonic-electromagnetic-fields",
    "href": "work/textbooks/balanis.html#time-varying-and-time-harmonic-electromagnetic-fields",
    "title": "Advanced Engineering Electromagnetics - C. Balanis",
    "section": "",
    "text": "Expand\n\n\nWho is James Clerk Maxwell?\n\n\n\nAnswer\n\n\n\n\nJames Clerk Maxwell\n\n\nA Scottish physicist and mathematician that lived from 1831 to 1879.\nThe Father of Modern Physics\n\nSee my notes on Dan Fleisch’s A student’s guide to Maxwell’s Equations for detailed explanation of the differential and integral forms of the four maxwell’s equations.\n\n\n\n\n\n\nExpand\n\n\n\n\n\n\n\n\nExpand\n\n\n\nWhat is Circuit Theory?\n\n\n\nAnswer\n\nA special case of electromagnetic theory, when the physical dimensions of the circuit are small compared to the wavelength."
  },
  {
    "objectID": "work/textbooks/balanis.html#electrical-properties-of-matter",
    "href": "work/textbooks/balanis.html#electrical-properties-of-matter",
    "title": "Advanced Engineering Electromagnetics - C. Balanis",
    "section": "2 Electrical Properties of Matter",
    "text": "2 Electrical Properties of Matter\n\nIntroduction\n\n\nExpand\n\n\n\n\n\nDielectrics, Polarization, and Permittivity\n\n\nExpand\n\n\n\n\n\nMagnetics, Magnetization, and Permeability\n\n\nExpand\n\n\n\n\n\nCurrent, Conductors, and Conductivity\n\n\nExpand\n\n\nCurrent\n\n\n\nConductors\n\n\n\nConductivity"
  },
  {
    "objectID": "work/textbooks/balanis.html#wave-equation-and-its-solutions",
    "href": "work/textbooks/balanis.html#wave-equation-and-its-solutions",
    "title": "Advanced Engineering Electromagnetics - C. Balanis",
    "section": "3 Wave Equation and Its Solutions",
    "text": "3 Wave Equation and Its Solutions\n\nIntroduction\n\n\nExpand\n\n\n\n\n\nTime-Varying Electromagnetic Fields\n\n\nExpand\n\n\n\n\n\nTime-Harmonic Electromagnetic Fields\n\n\nExpand\n\n\n\n\n\nSolution to the Wave Equation\n\n\nExpand\n\n\nRectangular Coordinate System\n\n\n\nCylindrical Coordinate System\n\n\n\nSpherical Coordinate System"
  },
  {
    "objectID": "work/textbooks/balanis.html#wave-propagation-and-polarization",
    "href": "work/textbooks/balanis.html#wave-propagation-and-polarization",
    "title": "Advanced Engineering Electromagnetics - C. Balanis",
    "section": "4 Wave Propagation and Polarization",
    "text": "4 Wave Propagation and Polarization\n\nIntroduction\n\n\nExpand\n\n\n\n\n\nTransverse Electromagnetic Modes\n\n\nExpand\n\n\n\n\n\nTransverse Electromagnetic Modes in Lossy Media\n\n\nExpand\n\n\n\n\n\nPolarization\n\n\nExpand\n\n\n\n\n\nExercises\n\n\nExpand"
  },
  {
    "objectID": "work/textbooks/balanis.html#reflection-and-transmission",
    "href": "work/textbooks/balanis.html#reflection-and-transmission",
    "title": "Advanced Engineering Electromagnetics - C. Balanis",
    "section": "5 Reflection and Transmission",
    "text": "5 Reflection and Transmission\n\nIntroduction\n\n\nExpand\n\n\n\n\n\nNormal Incidence - Lossless Media\n\n\nExpand\n\n\n\n\n\nOblique Incidence - Lossless Media\n\n\nExpand\n\n\nPerpendicular Polarization\n\n\n\nParallel Polarization\n\n\n\nTotal Transmission - Brewster Angle\n\n\n\nTotal Reflection - Critical Angle"
  }
]