% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Alex Meng's Notes},
  pdfauthor={Alex Meng},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Alex Meng's Notes}
\author{Alex Meng}
\date{2025-06-06}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

If you are reading this, you may be interesed in seeing what is ``Alex's
Notes''.

These notes are just things that I am documenting, that I wish could
become a useful resource for my future students, either when I TA or
become a professor.

Here's how to learn anything:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write it out! (Document, Code along)
\item
  EXPERIMENT and explore
\item
  Visualize things you don't understand
\item
  Ask Questions
\item
  Answer Exercise and Problems (stretch your knowledge)
\item
  Share with like-minded individuals
\end{enumerate}

\bookmarksetup{startatroot}

\chapter*{Deep Learning Systems}\label{deep-learning-systems}
\addcontentsline{toc}{chapter}{Deep Learning Systems}

\markboth{Deep Learning Systems}{Deep Learning Systems}

In this set of notes, we will create a minimal version of PyTorch /
Tensorflow from scratch, of what I call ``PyStickOnFire''.

\section*{Chapter 1: Machine Learning
Refresher}\label{chapter-1-machine-learning-refresher}
\addcontentsline{toc}{section}{Chapter 1: Machine Learning Refresher}

\markright{Chapter 1: Machine Learning Refresher}

The (Supervised) Machine learning idea: we take a bunch of labeled data,
feed them to a machine learning algorithm, and it outputs a ``program''
that solves the task.

\[\text{Training Dataset X} \rightarrow \boxed{\text{Machine Learning Algorithm}} \rightarrow \text{Model }h\]

We will focus on what the machine learning algorithm box contains. In
general, it consists of three things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The hypothesis class (the structure of \(h\) in terms of a set of
  parameters)
\item
  The loss function (specifies how good a given hypothesis is)
\item
  An optimization method (the way to minimize the loss function)
\end{enumerate}

All alogrithms in machine learning fit in this structure. Let's look at
\textbf{softmax regression} to illustrate these three basic components.

\subsection*{Multi-class Classification (Softmax
Regression)}\label{multi-class-classification-softmax-regression}
\addcontentsline{toc}{subsection}{Multi-class Classification (Softmax
Regression)}

Consider a \emph{k-class classification setting}, where we have

\begin{itemize}
\tightlist
\item
  training data:
  \[x^{(i)} \in \mathbb{R}^{n}, y^{(i)} \in \{1, \dots, k \} \text{ for } i = 1, \dots, m\]

  \begin{itemize}
  \tightlist
  \item
    \(n =\) dimensionality of input data
  \item
    \(k =\) number of different classes / labels
  \item
    \(m =\) number of data points in the training data
  \end{itemize}
\end{itemize}

where the training data are vectors that looks like
\[X = \{ \begin{bmatrix} x^{(1)}_1 \\ x^{(1)}_2 \\ \vdots \\ x^{(1)}_n \end{bmatrix} , \dots, \begin{bmatrix} x^{(m)}_1 \\ x^{(m)}_2 \\ \vdots \\ x^{(m)}_n \end{bmatrix} \}\]
and the labels are just a set of scalars of size \(k\).

\subsection*{1st Element: The Hypothesis
Function}\label{st-element-the-hypothesis-function}
\addcontentsline{toc}{subsection}{1st Element: The Hypothesis Function}

The hypothesis function is a mapping from one input to one output.
(Duhh\ldots{} just like every other function there is).
\[h: \mathbb{R^n} \rightarrow \mathbb{R^k}\]
\[h(x) = \begin{bmatrix} h_1(x) \\ h_2(x) \\ \vdots \\ h_k(x)\end{bmatrix}\]

So what really is \(h_i(x)\)? It is the hypothesis, the ``belief'', the
probability of how likely \(x\) maps to class \(i\).

A \textbf{linear hypothesis function} uses matrix multiplication, or
some other linear way, for this transformation:

\[h_\theta(x) = \theta^T x\]

for parameters \(\theta \in \mathbb{R^{n \times k}}\) (\(n\) rows and
\(k\) columns, so transpose becomes \(k \times n\), and
\(x \in \mathbb{R^{n \times 1}}\), so multiplication will work). Now we
say \(h_\theta\) because \(\theta\) is the parameters.

Notice how so far we only have one input and one output, \(h\) is only
working on one instance of the training set. However, in order to
implement these operations efficiently in the future, we shall use the
\textbf{matrix batch notation}.

\[X \in \mathbb{R^{m \times n}} = \begin{bmatrix} -x^{(1)^{T}}- \\ -x^{(2)^{T}}- \\ \vdots \\ -x^{(m)^{T}}- \end{bmatrix}\]

\[y \in \{ 1, \dots, k \}^m = \begin{bmatrix} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(m)}  \end{bmatrix}\]

\[h_\theta(X) = \begin{bmatrix} -h_\theta(x^{(1)})^{T}- \\ -h_\theta(x^{(2)})^{T}- \\ \vdots \\ -h_\theta(x^{(m)})^{T}- \end{bmatrix} = \begin{bmatrix} -x^{(1)^{T}} \theta- \\ -x^{(2)^{T}} \theta- \\ \vdots \\ -x^{(m)^{T}} \theta- \end{bmatrix} = X\theta\]

\begin{itemize}
\tightlist
\item
  \(n =\) dimensionality of input data
\item
  \(k =\) number of different classes / labels
\item
  \(m =\) number of data points in the training data
\end{itemize}

Each row is for a data point, the first example is in first row
(originally a column vector, now we transposed it to row vector), and
the second example is in second row, and so on\ldots{} Note that this is
not merely a notation change, but rather how to implement them more
efficiently in code later on.

\subsection*{2nd Element: The Loss
Function}\label{nd-element-the-loss-function}
\addcontentsline{toc}{subsection}{2nd Element: The Loss Function}

How are we going to evaluate the quality of our predictions?

\textbf{Classification Error}

\[l_{err}(h(x),y) = \begin{cases} 0, & \text{if } argmax_i h_i(x) = y \\ 1, & \text{otherwise} \end{cases}\]

The error is not differentiable, so it is not good for optimization.

\textbf{A better choice: Cross-Entropy Loss or Softmax}

The idea is that we want to map our outputs into being actual
probabilities

\[h_i(x) \rightarrow prob[label == i]\]

Probability has to be positive and sum to 1. In order to ensure
\(h_i(x)\) is positive, we can exponentiate it. In order to ensure all
\(h_i(x)'s\) to sum to 1, we need to normalize them.

\[prob[label == i] = normalize(\exp(h(x)))= \frac{\exp(h_i(x))}{\sum_{j = 1}^{k} \exp(h_j(x))} = softmax(h(x))\]

This is called the \textbf{softmax operation}, a mapping between scalar
values and a probability distribution.

So now we have a probability, We need some way of quantifying whether
the vector of probabilities \(softmax(h(x))\) is good or not. We want
\(prob[label == y]\) to be high, as large as possible, so the loss
function idea can be minimizing the negative of this probability (double
negative makes a positive!).

\[l_{cross-entropy} (h(x), y) = - prob[label = y]\]

Because minimizing probabilities is not numerically good: Probabilities
are bounded between \(0\) and \(1\), so their gradients near \(0\) can
become tiny (vanishing gradients). Logs transform that range \((0,1)\)
into \((âˆ’\infty,0)\), making the loss surface smoother and the gradients
more useful. So we take the log of it

\[l_{ce} (h(x), y) = - log(prob[label = y]) = -h_y(x) + log \sum_{j=1}^{k} exp(h_j(x))\]

This is commonly known as the \textbf{negative log loss} or
\textbf{cross-entropy loss}. This is also a case of \emph{convex
optimization}.

\subsection*{3rd Element: Optimization}\label{rd-element-optimization}
\addcontentsline{toc}{subsection}{3rd Element: Optimization}

How do we find good values for \(\theta\)?

This element we will spend the most time to cover because we not only
what to know what the optimization is, but how we are optimizing it.

\emph{The following problem is the problem that almost all machine
algorithms are solving.} Here is the problem,

\[
\min_{\theta} \frac{1}{m} \sum_{i=1}^{m} l(h_\theta(x^{(i)}), y^{(i)})
\]

We are searching over all possible values of \(\theta\), the one that
minimizes the \emph{average} loss. For example, here's softmax
regression,

\[
\min_{\theta} f(\theta) = \min_{\theta} \frac{1}{m} \sum_{i=1}^{m} l_{ce}(\theta^T x^{(i)}, y^{(i)})
\]

\emph{Now we know the ``what'', but, how do we find that?} How do we
solve \(\min_{\theta} f(\theta) ?\)

\subsubsection*{The Gradient}\label{the-gradient}
\addcontentsline{toc}{subsubsection}{The Gradient}

For our \(f(\theta)\) (the function that we are trying to minimize),
remember, this function takes the parameter (which is of dimension n
examples by k output classes) and outputs a loss scalar, in other words
\[f: \mathbb{R^{n \times k}} \rightarrow \mathbb{R}\]

\[f(\theta) \in \mathbb{R}\]

Remember that the gradient is a multidimensional derivative that has a
direction, which points to the direction of \emph{sharpest increase
(locally)}. The gradient operator can only act on a scalar and return a
vector.

Here is the definition of the gradient in our case,

\[\nabla_\theta f(\theta) = \begin{bmatrix} 
\frac{\partial f}{\partial \theta_{11}} \frac{\partial f}{\partial \theta_{12}} \dots \frac{\partial f}{\partial \theta_{1k}} \\ 
\frac{\partial f}{\partial \theta_{21}} \frac{\partial f}{\partial \theta_{22}}  \dots \frac{\partial f}{\partial \theta_{2k}} \\ 
\vdots \\
\frac{\partial f}{\partial \theta_{n1}} \frac{\partial f}{\partial \theta_{n2}}  \dots \frac{\partial f}{\partial \theta_{nk}} 
\end{bmatrix} \in \mathbb{R^{n \times k}}\]

The derivative of a function is the slope of the function, change in
\(y\) over change in \(x\).

\subsubsection*{Gradient Descent}\label{gradient-descent}
\addcontentsline{toc}{subsubsection}{Gradient Descent}

If the gradient points in the direction of maximum increase, to minimize
a function, we can repeatedly step in the opposite direction. In other
words,

\[\theta = \theta - \alpha \nabla_\theta f(\theta)\]

where \(\alpha\) is called the \emph{learning rate} or \emph{step size}.
Note that the learning rate must be positive for the stepping direction
to be in the negative direction from the gradient. \textbf{This basic
idea powers all deep learning. It is really hard to encapsulate how
impactful this one line of math has been.}

The choice of the step size \(\alpha\) is really really really
important. Too small slows down progress, but too big will overshoot.

\subsubsection*{Stochastic Gradient
Descent}\label{stochastic-gradient-descent}
\addcontentsline{toc}{subsubsection}{Stochastic Gradient Descent}

We split up the dataset into \emph{minibatches}, which are subsets of
data of size \(B\).

We repeat the process of sampling minibatches and taking steps to update
\(\theta\).

\begin{itemize}
\tightlist
\item
  Sample: \(X \in \mathbb{R^{B \times n}}, y \in \{ 1, \dots, k\}^B\)
\item
  Update:
  \(\theta = \theta - \frac{\alpha}{B} \sum_{i=1}^{B} \nabla_\theta l(h_\theta(x^{(i)}), y^{(i)})\)
\end{itemize}

\subsubsection*{Calculating the gradient in
practice}\label{calculating-the-gradient-in-practice}
\addcontentsline{toc}{subsubsection}{Calculating the gradient in
practice}

In order to calculate the gradient of \(f(\theta)\), which is
essentially the sum of gradients,

\[\nabla_\theta \frac{1}{m} \sum_{i=1}^{m} l(h_\theta(x^{(i)}), y^{(i)}) =  \frac{1}{m} \sum_{i=1}^{m} \nabla_\theta l(h_\theta(x^{(i)}), y^{(i)})\]

We have to calculate the gradient \(m\) times, which is very expensive.
\emph{Can we reduce the number of times we take gradient?} Yes, and
that's what we actually do in practice.

As an example, how do we compute the gradient for softmax objective? We
can do it by hand, but it is cumbersome. You can use something like
chain rule. We want derivative of a vector with respect to a
matrix\ldots\ldots We need some more general and generic way to take
derivatives. What can we do?

In practice, we just specify the hypothesis function and the loss
function, and use \textbf{Automatic Differentiation}. But how?

We can either do it through the ``right'' way, use matrix differential
calculus, jacobians, kronecker products, and vectorization. Or we could
take a shortcut (\textbf{what everyone actually does}): We pretend
everything is scalar, use typical chain rule, and then
transpose/rearrange outputs to make sizes work, and then check your
answers numerically.

\[\frac{\partial}{\partial \theta} l_{ce} (\theta^T x, y)= \frac{\partial l_{ce} (\theta^T x, y)}{\partial \theta^T x} \cdot \frac{\partial \theta^T x}{\partial \theta}\]

\bookmarksetup{startatroot}

\chapter*{Optics}\label{optics}
\addcontentsline{toc}{chapter}{Optics}

\markboth{Optics}{Optics}

\section*{Q1: One Dimensional Wave
Equation}\label{q1-one-dimensional-wave-equation}
\addcontentsline{toc}{section}{Q1: One Dimensional Wave Equation}

\markright{Q1: One Dimensional Wave Equation}

The wave equation is given by

\[\psi(x,t) = \frac{3}{[10(x - vt)^2 + 1]}\]

Show, using brute force, that this is a solution to the one dimensional
differential wave equation.

Great! Let's start with what is a wave.

\textbf{\emph{Def.}} \emph{A classical traveling wave is a
self-sustaining disturbance \(\psi\) of a medium, and the disturbance
\(\psi\) moves through space transporting energy and momentum.}

Everything is waves.

Sound! A type of \textbf{longitudinal} wave, where the displacement
vector points parallel to the direction of motion.

Guitar string! A type of \textbf{transverse} wave, where the
displacement vector points perpendicular to the direction of motion.

A wave is not a stream of particles! Because the individual atoms stay
in equilibrium, but only the disturbance advances through them. Leonardo
da Vinci was one of the first person to realize waves does not transport
the medium through which it travels.

Imagine disturbance \(\psi\) moves in positive direction \(x\) with
constant velocity \(v\).

\[\psi = f(x,t)\]

What is \(f(x,0)\)? it is the shape (aka the \textbf{profile}) of
\(\psi\) at \(t=0\). For example, try visualizing \(f(x) = e^{-ax^2}\),
you'll see that it is a \textbf{gaussian function}. Setting \(t=0\) is
taking a snapshot of the pulse as it travels by.

In order to understand this better, let's ignore \(t\) by introducing a
coordinate system \(S^{'}\) that travels with the pilse at the speed
\(v\). As we move with \(S^{'}\), the wave looks stationary! So

\[\psi = f \left( x^{'} \right)\]

where \(x^{'} = x - vt\), because after time \(t\) the same point on
\(\psi\) moved a distance of \(vt\).

\subsubsection*{General Form of One Dimensional Wave
Function}\label{general-form-of-one-dimensional-wave-function}
\addcontentsline{toc}{subsubsection}{General Form of One Dimensional
Wave Function}

\[\psi(x,t) = f(x - vt)\]

\href{https://en.wikipedia.org/wiki/Jean_le_Rond_d\%27Alembert}{Jean Le
Rond d'Alembert} was the one that brought partial differential equations
to physics and formulated the differential wave equation.

\bookmarksetup{startatroot}

\chapter*{Problem Solving}\label{problem-solving}
\addcontentsline{toc}{chapter}{Problem Solving}

\markboth{Problem Solving}{Problem Solving}

Being a quant is knowing how to solve problems with logic, math, and
intuition. These Problems come from
\href{https://academyflex.com/wp-content/uploads/2024/03/a-practical-guide-to-quantitative-finance-interviews.pdf}{A
practical guide to Quantitative Finance Interviews by Xinfeng Zhou}.

\section*{1 Problem Simplification}\label{problem-simplification}
\addcontentsline{toc}{section}{1 Problem Simplification}

\markright{1 Problem Simplification}

\subsection*{Screwy Pirates}\label{screwy-pirates}
\addcontentsline{toc}{subsection}{Screwy Pirates}

Five pirates looted a chest full of 100 gold coins. Being a bunch of
democratic pirates, they agree on the following method to divide the
loot:

The most senior pirate will propose a distribution of the coins. All
pirates, \emph{including the most senior pirate}, will then vote. If at
least \(50\%\) of the pirates (\(3\) pirates in this case) accept the
proposal, the gold is divided as proposed. If not, the most senior
pirate will be fed to shark and the process starts over with the next
most senior pirate\ldots{} The process is repeated until a plan is
approved. You can assume that all pirates are perfectly rational: they
want to stay alive first and to get as much gold as possible second.
Finally, being blood-thirsty pirates, they want to have fewer pirates on
the boat if given a choice between otherwise equal outcomes.

How will the gold coins be divided in the end?

Answer

I have no idea what the five pirates will do, lemme consider a simpler
case, 1 pirate.

1 pirate. Pirate 1 propose to distribute all 100 gold coins to himself,
and accept the proposal.

\[100 \text{ coins to pirate 1}\]

2 pirates. Pirate 2 proposes to get all the gold, 50\% good, gets all
the gold.

\[100 \text{ coins to pirate 2}\]

3 pirates. From the perspective of pirate 1, pirate 1 gets nothing if
pirate 3 pirate 3 gets voted out (back to case 2), so pirate 1 will try
to make pirate 3 win, iff pirate 1 gets at least some benefits. Pirate 3
knows that, so pirate 3 will give 1 coin to pirate 1 and 99 coins to
pirate 3, since pirate 1 will think anything is better than nothing.

\[1 \text{ coin to pirate 1}, 99 \text{ coins to pirate 3}\]

4 pirates. If pirate 4 gives to pirate 2, pirate 2 will vote for pirate
4 because if he doesn't, it will be back to 3 pirates case where he
doesn't get anything\ldots So

\[1 \text{ coin pirate 2}, 99 \text{ coins pirate 4}\]

5 pirates. Pirate 5 will give coinds to pirate 1 and pirate 3, because
doing that will allow them to get some coins, where if he gets voted
out, in 4 pirates case they don't get anything\ldots So

\[\boxed{1 \text{ coin for pirate 1}, 1 \text{ coin for pirate 3}, 98 \text{ coins for pirate 5}}\]

We can actually formualte a generalizable law from this using
mathematics.




\end{document}
